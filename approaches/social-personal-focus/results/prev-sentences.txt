2024-12-06 21:18:44,394 - HVD - INFO - Initializing tokenizer for model: microsoft/deberta-base
2024-12-06 21:18:44,652 - HVD - INFO - Loading lexicon embeddings for: No lexicon used
2024-12-06 21:18:44,652 - HVD - INFO - Preparing datasets for training and validation
2024-12-06 21:19:02,958 - HVD - INFO - Arguments validated successfully.
2024-12-06 21:19:03,919 - HVD - INFO - Using CUDA for training.
2024-12-06 21:19:05,176 - HVD - INFO - TRAINING
2024-12-06 21:19:05,176 - HVD - INFO - ========
2024-12-06 21:19:05,176 - HVD - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: None
Batch size: 2
Number of epochs: 9
Learning rate: 2.07e-05
Weight decay: 1.02e-05
Gradient accumulation steps: 4
Early stopping patience: 3
Previous sentences used: Yes
Using lexicon: No
Adding linguistic features: No
Number of categories (lexicon): 0

2024-12-06 21:19:05,181 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.5765, 'grad_norm': 99319.1328125, 'learning_rate': 2.0288845191276368e-05, 'epoch': 0.18}
{'loss': 0.5708, 'grad_norm': 63734.6328125, 'learning_rate': 1.9877690382552734e-05, 'epoch': 0.36}
{'loss': 0.5618, 'grad_norm': 154378.640625, 'learning_rate': 1.94665355738291e-05, 'epoch': 0.54}
{'loss': 0.5567, 'grad_norm': 77273.515625, 'learning_rate': 1.905538076510547e-05, 'epoch': 0.71}
{'loss': 0.5595, 'grad_norm': 117034.2265625, 'learning_rate': 1.8644225956381836e-05, 'epoch': 0.89}
4
{'eval_loss': 0.5515891313552856, 'eval_f1-score': {'Social Focus': 0.22, 'Personal Focus': 0.12}, 'eval_marco-avg-f1-score': 0.17, 'eval_runtime': 503.7003, 'eval_samples_per_second': 29.589, 'eval_steps_per_second': 7.397, 'epoch': 1.0}
{'loss': 0.548, 'grad_norm': 138842.796875, 'learning_rate': 1.8233071147658203e-05, 'epoch': 1.07}
{'loss': 0.5162, 'grad_norm': 165792.71875, 'learning_rate': 1.7821916338934572e-05, 'epoch': 1.25}
{'loss': 0.5098, 'grad_norm': 229778.1875, 'learning_rate': 1.741076153021094e-05, 'epoch': 1.43}
{'loss': 0.5221, 'grad_norm': 215714.78125, 'learning_rate': 1.6999606721487308e-05, 'epoch': 1.61}
{'loss': 0.5189, 'grad_norm': 188138.296875, 'learning_rate': 1.6588451912763674e-05, 'epoch': 1.79}
{'loss': 0.5174, 'grad_norm': 218244.03125, 'learning_rate': 1.617729710404004e-05, 'epoch': 1.97}
4
{'eval_loss': 0.5661277770996094, 'eval_f1-score': {'Social Focus': 0.31, 'Personal Focus': 0.28}, 'eval_marco-avg-f1-score': 0.3, 'eval_runtime': 504.0932, 'eval_samples_per_second': 29.566, 'eval_steps_per_second': 7.391, 'epoch': 2.0}
{'loss': 0.4513, 'grad_norm': 379608.46875, 'learning_rate': 1.576614229531641e-05, 'epoch': 2.14}
{'loss': 0.4399, 'grad_norm': 379560.0, 'learning_rate': 1.5354987486592777e-05, 'epoch': 2.32}
{'loss': 0.4376, 'grad_norm': 493172.625, 'learning_rate': 1.4943832677869145e-05, 'epoch': 2.5}
{'loss': 0.4417, 'grad_norm': 485462.0, 'learning_rate': 1.4532677869145513e-05, 'epoch': 2.68}
{'loss': 0.439, 'grad_norm': 286244.34375, 'learning_rate': 1.4121523060421879e-05, 'epoch': 2.86}
4
{'eval_loss': 0.6281338334083557, 'eval_f1-score': {'Social Focus': 0.35, 'Personal Focus': 0.34}, 'eval_marco-avg-f1-score': 0.34, 'eval_runtime': 505.0082, 'eval_samples_per_second': 29.512, 'eval_steps_per_second': 7.378, 'epoch': 3.0}
{'loss': 0.414, 'grad_norm': 215436.1875, 'learning_rate': 1.3710368251698247e-05, 'epoch': 3.04}
{'loss': 0.3413, 'grad_norm': 616632.75, 'learning_rate': 1.3299213442974615e-05, 'epoch': 3.22}
{'loss': 0.3495, 'grad_norm': 429679.5, 'learning_rate': 1.2888058634250981e-05, 'epoch': 3.4}
{'loss': 0.3403, 'grad_norm': 495563.9375, 'learning_rate': 1.2476903825527349e-05, 'epoch': 3.57}
{'loss': 0.3435, 'grad_norm': 595980.6875, 'learning_rate': 1.2065749016803719e-05, 'epoch': 3.75}
{'loss': 0.3514, 'grad_norm': 512176.46875, 'learning_rate': 1.1654594208080083e-05, 'epoch': 3.93}
4
{'eval_loss': 0.7297266125679016, 'eval_f1-score': {'Social Focus': 0.41, 'Personal Focus': 0.3}, 'eval_marco-avg-f1-score': 0.36, 'eval_runtime': 504.5922, 'eval_samples_per_second': 29.537, 'eval_steps_per_second': 7.384, 'epoch': 4.0}
{'loss': 0.2863, 'grad_norm': 560664.6875, 'learning_rate': 1.1243439399356453e-05, 'epoch': 4.11}
{'loss': 0.2524, 'grad_norm': 645250.375, 'learning_rate': 1.083228459063282e-05, 'epoch': 4.29}
{'loss': 0.2557, 'grad_norm': 782485.4375, 'learning_rate': 1.0421129781909187e-05, 'epoch': 4.47}
{'loss': 0.2507, 'grad_norm': 649472.75, 'learning_rate': 1.0009974973185555e-05, 'epoch': 4.65}
{'loss': 0.2588, 'grad_norm': 283641.3125, 'learning_rate': 9.598820164461923e-06, 'epoch': 4.83}
4
{'eval_loss': 0.9331303238868713, 'eval_f1-score': {'Social Focus': 0.39, 'Personal Focus': 0.35}, 'eval_marco-avg-f1-score': 0.37, 'eval_runtime': 504.4668, 'eval_samples_per_second': 29.544, 'eval_steps_per_second': 7.386, 'epoch': 5.0}
{'loss': 0.2496, 'grad_norm': 272039.03125, 'learning_rate': 9.18766535573829e-06, 'epoch': 5.0}
{'loss': 0.1825, 'grad_norm': 748031.9375, 'learning_rate': 8.776510547014657e-06, 'epoch': 5.18}
{'loss': 0.182, 'grad_norm': 574192.375, 'learning_rate': 8.365355738291025e-06, 'epoch': 5.36}
{'loss': 0.1882, 'grad_norm': 731155.5625, 'learning_rate': 7.954200929567393e-06, 'epoch': 5.54}
{'loss': 0.193, 'grad_norm': 972478.125, 'learning_rate': 7.543046120843761e-06, 'epoch': 5.72}
{'loss': 0.1764, 'grad_norm': 729991.75, 'learning_rate': 7.131891312120128e-06, 'epoch': 5.9}
4
{'eval_loss': 1.041929841041565, 'eval_f1-score': {'Social Focus': 0.37, 'Personal Focus': 0.33}, 'eval_marco-avg-f1-score': 0.35, 'eval_runtime': 504.6192, 'eval_samples_per_second': 29.535, 'eval_steps_per_second': 7.384, 'epoch': 6.0}
{'loss': 0.1716, 'grad_norm': 857091.75, 'learning_rate': 6.720736503396496e-06, 'epoch': 6.08}
{'loss': 0.1309, 'grad_norm': 570685.8125, 'learning_rate': 6.309581694672863e-06, 'epoch': 6.26}
{'loss': 0.1348, 'grad_norm': 889170.125, 'learning_rate': 5.898426885949231e-06, 'epoch': 6.43}
{'loss': 0.1314, 'grad_norm': 401033.59375, 'learning_rate': 5.487272077225598e-06, 'epoch': 6.61}
{'loss': 0.1298, 'grad_norm': 809986.25, 'learning_rate': 5.076117268501966e-06, 'epoch': 6.79}
{'loss': 0.1294, 'grad_norm': 1293246.75, 'learning_rate': 4.664962459778333e-06, 'epoch': 6.97}
4
{'eval_loss': 1.3447437286376953, 'eval_f1-score': {'Social Focus': 0.37, 'Personal Focus': 0.34}, 'eval_marco-avg-f1-score': 0.36, 'eval_runtime': 503.4194, 'eval_samples_per_second': 29.606, 'eval_steps_per_second': 7.401, 'epoch': 7.0}
{'loss': 0.1053, 'grad_norm': 2192412.0, 'learning_rate': 4.253807651054701e-06, 'epoch': 7.15}
{'loss': 0.0974, 'grad_norm': 316533.1875, 'learning_rate': 3.842652842331068e-06, 'epoch': 7.33}
{'loss': 0.0984, 'grad_norm': 124733.3984375, 'learning_rate': 3.431498033607436e-06, 'epoch': 7.51}
{'loss': 0.098, 'grad_norm': 833109.5, 'learning_rate': 3.020343224883804e-06, 'epoch': 7.69}
{'loss': 0.0941, 'grad_norm': 483170.875, 'learning_rate': 2.6091884161601712e-06, 'epoch': 7.86}
4
{'eval_loss': 1.6332167387008667, 'eval_f1-score': {'Social Focus': 0.4, 'Personal Focus': 0.34}, 'eval_marco-avg-f1-score': 0.37, 'eval_runtime': 504.4382, 'eval_samples_per_second': 29.546, 'eval_steps_per_second': 7.386, 'epoch': 8.0}
{'train_runtime': 32100.8498, 'train_samples_per_second': 12.549, 'train_steps_per_second': 0.784, 'train_loss': 0.3167625930077056, 'epoch': 8.0}
2024-12-07 06:14:06,553 - HVD - INFO - 

VALIDATION
2024-12-07 06:14:06,553 - HVD - INFO - ==========
4
2024-12-07 06:22:29,950 - HVD - INFO - Social Focus: 0.39
2024-12-07 06:22:29,950 - HVD - INFO - Personal Focus: 0.35
2024-12-07 06:22:29,950 - HVD - INFO - Macro average: 0.37
2024-12-07 06:22:31,138 - HVD - INFO - SAVE to models/prev-sentences
