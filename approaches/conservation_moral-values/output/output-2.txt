==========
==========
==========
===== Lex-LIWC-22_LingFeat =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-LIWC-22_LingFeat (based on Conservation = Baseline) =====
==========
----- Predicting Test -----
2025-05-29 14:37:43,249 - INFO - Using device: cuda
2025-05-29 14:37:43,372 - INFO - Hierarchical run ➜ 2843 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Face  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.32  Recall: 0.14  F1: 0.19

Label: Security: personal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.34  Recall: 0.34  F1: 0.34

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.38  Recall: 0.43  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.53  Recall: 0.42  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.43  Recall: 0.43  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.06  F1: 0.08

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.07  Recall: 0.03  F1: 0.05

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 7 labels: 0.28
==========
===== Lex-LIWC-22_LingFeat (based on Conservation = Lex-LIWC-22_LingFeat) =====
==========
----- Predicting Test -----
2025-05-29 14:38:32,804 - INFO - Using device: cuda
2025-05-29 14:38:33,048 - INFO - Hierarchical run ➜ 2937 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Face  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.33  Recall: 0.15  F1: 0.21

Label: Security: personal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.33  Recall: 0.33  F1: 0.33

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.94  F1: 0.94
  Class 1 (positive)
    Precision: 0.38  Recall: 0.45  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.43  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.43  Recall: 0.42  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.17  Recall: 0.09  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.05  Recall: 0.03  F1: 0.04

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 7 labels: 0.28
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Lex-LIWC-22_LingFeat (based on Conservation = Lex-LIWC-22_LingFeat) =====
==========
----- Predicting Test -----
2025-05-29 14:39:23,153 - INFO - Using device: cuda
2025-05-29 14:39:23,277 - INFO - Hierarchical run ➜ 5934 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Face  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.25  F1: 0.24

Label: Security: personal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.46  F1: 0.33

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.85  F1: 0.91
  Class 1 (positive)
    Precision: 0.27  Recall: 0.64  F1: 0.38

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.39  Recall: 0.62  F1: 0.48

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.61  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.11  Recall: 0.20  F1: 0.14

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.03  Recall: 0.07  F1: 0.04

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 7 labels: 0.29
