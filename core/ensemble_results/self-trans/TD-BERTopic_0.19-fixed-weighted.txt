Parsing arguments...
Building threshold map...
Computing weights from validation Macro-F1 …
Weights: {'1_TD-BERTopic_0.19_Baseline-val.tsv': '0.249', '1_TD-BERTopic_0.19_Lex-Schwartz-val.tsv': '0.249', '1_TD-BERTopic_0.19_Lex-EmoLex-val.tsv': '0.247', '1_TD-BERTopic_0.19_Lex-MFD-val.tsv': '0.256'}
Assembling...
Forward selection...
Seed model: 1_TD-BERTopic_0.19_Lex-MFD-val.tsv  (Macro-F1 = 0.29580)

Forward selection (weighted voting):
[Round 1]. Current Macro-Average F1 = 0.29580

Testing candidates: ['1_TD-BERTopic_0.19_Baseline-val.tsv', '1_TD-BERTopic_0.19_Lex-Schwartz-val.tsv', '1_TD-BERTopic_0.19_Lex-EmoLex-val.tsv']
  1_TD-BERTopic_0.19_Baseline-val.tsv lower=-0.01024 p=0.53640
  1_TD-BERTopic_0.19_Lex-Schwartz-val.tsv lower=-0.01195 p=0.95380
  1_TD-BERTopic_0.19_Lex-EmoLex-val.tsv lower=-0.01264 p=0.70420

Selected: ['1_TD-BERTopic_0.19_Lex-MFD-val.tsv']
Evaluating...

=== Final Weighted Ensemble (['1_TD-BERTopic_0.19_Lex-MFD-val.tsv']) ===
Macro-F1 Seed = 0.29580, Ensemble = 0.29580
One-sided lower 95% ΔF1 = 0.00000
p(ens>base) = 1.00000 -> significant? no
No per-label discordance on final ensemble.
Saving ensemble predictions...
Ensemble probabilities written to ../approaches/self-trans_moral-values/output/TD-BERTopic_0.19-fixed-weighted-champion-val.tsv
