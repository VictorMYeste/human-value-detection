2025-04-14 09:29:02,639 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-14 09:29:02,642 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-14 09:29:09,566 - INFO - Setting random seed to 42
2025-04-14 09:29:09,567 - INFO - Running training for labels: ['Social Focus', 'Personal Focus']
2025-04-14 09:29:09,567 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-04-14 09:29:10,345 - INFO - Loading lexicon embeddings for: No lexicon used
2025-04-14 09:29:10,345 - INFO - Preparing datasets for training and validation
2025-04-14 09:31:09,019 - INFO - Adding Previous Sentences Labels features with num_categories = 0
2025-04-14 09:32:14,074 - INFO - Adding Previous Sentences Labels features with num_categories = 0
2025-04-14 09:32:15,114 - INFO - Arguments validated successfully.
2025-04-14 09:32:15,118 - INFO - Previous sentences or augmented data detected. Adjusting batch size: 4 -> 2 and gradient accumulation steps: 4 -> 8
2025-04-14 09:32:15,118 - INFO - Clearing old checkpoints in models/checkpoints
2025-04-14 09:32:15,609 - INFO - Using CUDA for training.
2025-04-14 09:32:16,942 - INFO - TRAINING
2025-04-14 09:32:16,942 - INFO - ========
2025-04-14 09:32:16,942 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: None
Filter labels: ['Presence']
Batch size: 2
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 8
Early stopping patience: 4
Multilayer: No
Previous sentences used: Yes
Using lexicon: No
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 0
Using data augmentation with paraphrasing: No
Adding topic detection features: No
Applying token pruning: No

2025-04-14 09:32:16,945 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-04-14 09:32:16,949 - INFO - Rebuilding validation dataset with dynamically predicted previous labels.
{'loss': 0.598, 'grad_norm': 4.617373466491699, 'learning_rate': 1.8611111111111114e-05, 'epoch': 0.69}
{'eval_loss': 0.5615994930267334, 'eval_f1-score': {'Social Focus': 0.74, 'Personal Focus': 0.71}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 93.9078, 'eval_samples_per_second': 80.93, 'eval_steps_per_second': 20.233, 'epoch': 1.0}
2025-04-14 09:52:36,910 - INFO - Skipping evaluation for warm-up phase (epoch 0).
2025-04-14 09:57:14,983 - INFO - Updated evaluation dataset with dynamic previous label features.
{'loss': 0.4873, 'grad_norm': 4.81516170501709, 'learning_rate': 1.7222222222222224e-05, 'epoch': 1.39}
{'eval_loss': 0.5793566107749939, 'eval_f1-score': {'Social Focus': 0.74, 'Personal Focus': 0.71}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 95.0297, 'eval_samples_per_second': 79.975, 'eval_steps_per_second': 19.994, 'epoch': 2.0}
2025-04-14 10:17:38,078 - INFO - Skipping evaluation for warm-up phase (epoch 1).
2025-04-14 10:22:20,438 - INFO - Updated evaluation dataset with dynamic previous label features.
{'loss': 0.4382, 'grad_norm': 9.649624824523926, 'learning_rate': 1.5833333333333333e-05, 'epoch': 2.08}
{'loss': 0.3216, 'grad_norm': 10.474509239196777, 'learning_rate': 1.4444444444444446e-05, 'epoch': 2.77}
{'eval_loss': 0.6782737970352173, 'eval_f1-score': {'Social Focus': 0.76, 'Personal Focus': 0.68}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 94.9635, 'eval_samples_per_second': 80.031, 'eval_steps_per_second': 20.008, 'epoch': 3.0}
2025-04-14 10:47:28,845 - INFO - Updated evaluation dataset with dynamic previous label features.
{'loss': 0.2485, 'grad_norm': 8.240836143493652, 'learning_rate': 1.3055555555555557e-05, 'epoch': 3.47}
{'eval_loss': 0.8737848401069641, 'eval_f1-score': {'Social Focus': 0.72, 'Personal Focus': 0.7}, 'eval_macro-avg-f1-score': 0.71, 'eval_runtime': 94.9708, 'eval_samples_per_second': 80.025, 'eval_steps_per_second': 20.006, 'epoch': 4.0}
2025-04-14 11:12:42,116 - INFO - Updated evaluation dataset with dynamic previous label features.
{'loss': 0.1937, 'grad_norm': 1.883099913597107, 'learning_rate': 1.1666666666666668e-05, 'epoch': 4.16}
{'loss': 0.1427, 'grad_norm': 7.6812744140625, 'learning_rate': 1.0277777777777777e-05, 'epoch': 4.86}
{'eval_loss': 1.0218828916549683, 'eval_f1-score': {'Social Focus': 0.74, 'Personal Focus': 0.68}, 'eval_macro-avg-f1-score': 0.71, 'eval_runtime': 94.8035, 'eval_samples_per_second': 80.166, 'eval_steps_per_second': 20.041, 'epoch': 5.0}
2025-04-14 11:37:51,491 - INFO - Updated evaluation dataset with dynamic previous label features.
{'loss': 0.1095, 'grad_norm': 1.4140487909317017, 'learning_rate': 8.888888888888888e-06, 'epoch': 5.55}
{'eval_loss': 1.2114241123199463, 'eval_f1-score': {'Social Focus': 0.75, 'Personal Focus': 0.68}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 95.2894, 'eval_samples_per_second': 79.757, 'eval_steps_per_second': 19.939, 'epoch': 6.0}
2025-04-14 12:03:05,259 - INFO - Updated evaluation dataset with dynamic previous label features.
{'loss': 0.096, 'grad_norm': 2.783513069152832, 'learning_rate': 7.500000000000001e-06, 'epoch': 6.24}
{'loss': 0.0749, 'grad_norm': 1.4193590879440308, 'learning_rate': 6.111111111111112e-06, 'epoch': 6.94}
{'eval_loss': 1.3540040254592896, 'eval_f1-score': {'Social Focus': 0.74, 'Personal Focus': 0.7}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 95.0311, 'eval_samples_per_second': 79.974, 'eval_steps_per_second': 19.993, 'epoch': 7.0}
2025-04-14 12:28:17,706 - INFO - Updated evaluation dataset with dynamic previous label features.
{'train_runtime': 10559.7558, 'train_samples_per_second': 21.84, 'train_steps_per_second': 0.682, 'train_loss': 0.26926795843217016, 'epoch': 7.0}
2025-04-14 12:28:19,429 - INFO - 

VALIDATION
2025-04-14 12:28:19,429 - INFO - ==========
2025-04-14 12:34:35,965 - INFO - Updated evaluation dataset with dynamic previous label features.
2025-04-14 12:34:35,966 - INFO - Social Focus: 0.76
2025-04-14 12:34:35,966 - INFO - Personal Focus: 0.68
2025-04-14 12:34:35,966 - INFO - Macro average: 0.72
2025-04-14 12:34:36,018 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
