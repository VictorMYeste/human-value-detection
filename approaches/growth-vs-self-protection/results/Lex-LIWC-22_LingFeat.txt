2025-05-23 12:25:04,929 - INFO - PyTorch version 2.7.0+cu118 available.
2025-05-23 12:25:04,929 - INFO - PyTorch version 2.7.0+cu118 available.
2025-05-23 12:25:12,975 - INFO - Setting random seed to 42
2025-05-23 12:25:12,976 - INFO - Running training for labels: ['Growth Anxiety-Free', 'Self-Protection Anxiety-Avoidance']
2025-05-23 12:25:12,976 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-05-23 12:25:13,168 - INFO - Loading lexicon embeddings for: LIWC-22
2025-05-23 12:25:13,168 - INFO - Preparing datasets for training and validation
2025-05-23 12:25:37,063 - INFO - Loading en_core_web_sm for extra features
2025-05-23 12:25:37,593 - INFO - Adding Linguistic features
2025-05-23 12:30:20,381 - INFO - Loading en_core_web_sm for extra features
2025-05-23 12:30:20,695 - INFO - Adding Linguistic features
2025-05-23 12:31:55,950 - INFO - Arguments validated successfully.
2025-05-23 12:31:56,028 - INFO - Clearing old checkpoints in models/checkpoints
2025-05-23 12:31:57,699 - INFO - Using CUDA for training.
2025-05-23 12:31:59,384 - INFO - TRAINING
2025-05-23 12:31:59,384 - INFO - ========
2025-05-23 12:31:59,385 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: Lex-LIWC-22_LingFeat
Filter labels: []
Batch size: 4
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 4
Early stopping patience: 4
Multilayer: No
ResidualBlock: No
Previous sentences used: No
Using lexicon: LIWC-22
Adding linguistic features: Yes
Adding NER features: No
Number of categories (lexicon): 118
Using data augmentation with paraphrasing: No
Adding topic detection features: No
Applying token pruning: No

2025-05-23 12:31:59,387 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-05-23 12:32:00,309 - ERROR - An error occurred: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.cpp:77, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 'CUDA driver version is insufficient for CUDA runtime version'
Traceback (most recent call last):
  File "/home/vicyesmo/human-value-detection/approaches/growth-vs-self-protection/main.py", line 132, in <module>
    main()
  File "/home/vicyesmo/human-value-detection/approaches/growth-vs-self-protection/main.py", line 103, in main
    run_training(
  File "/home/vicyesmo/human-value-detection/core/runner.py", line 81, in run_training
    trainer = train(
  File "/home/vicyesmo/human-value-detection/core/training.py", line 268, in train
    trainer.train()
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1339, in prepare
    result = tuple(
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1469, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 835, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/torch/distributed/utils.py", line 282, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.cpp:77, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 'CUDA driver version is insufficient for CUDA runtime version'
2025-05-23 12:32:00,310 - ERROR - An error occurred: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.cpp:77, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 'CUDA driver version is insufficient for CUDA runtime version'
Traceback (most recent call last):
  File "/home/vicyesmo/human-value-detection/approaches/growth-vs-self-protection/main.py", line 132, in <module>
    main()
  File "/home/vicyesmo/human-value-detection/approaches/growth-vs-self-protection/main.py", line 103, in main
    run_training(
  File "/home/vicyesmo/human-value-detection/core/runner.py", line 81, in run_training
    trainer = train(
  File "/home/vicyesmo/human-value-detection/core/training.py", line 268, in train
    trainer.train()
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/transformers/trainer.py", line 2204, in _inner_training_loop
    model, self.optimizer = self.accelerator.prepare(self.model, self.optimizer)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1339, in prepare
    result = tuple(
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1340, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1215, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/accelerate/accelerator.py", line 1469, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 835, in __init__
    _verify_param_shape_across_processes(self.process_group, parameters)
  File "/home/vicyesmo/anaconda3/envs/hvd/lib/python3.9/site-packages/torch/distributed/utils.py", line 282, in _verify_param_shape_across_processes
    return dist._verify_params_across_processes(process_group, tensors, logger)
torch.distributed.DistBackendError: NCCL error in: /pytorch/torch/csrc/distributed/c10d/NCCLUtils.cpp:77, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.21.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 'CUDA driver version is insufficient for CUDA runtime version'
