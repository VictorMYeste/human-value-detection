
Label: Self-direction: thought  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.60  Recall: 0.02  F1: 0.03

Label: Self-direction: thought  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.60  Recall: 0.02  F1: 0.03

Label: Self-direction: action  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.97  Recall: 1.00  F1: 0.98
  Class 1 (positive)
    Precision: 0.44  Recall: 0.07  F1: 0.12

Label: Self-direction: action  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 1.00  F1: 0.98
  Class 1 (positive)
    Precision: 0.44  Recall: 0.07  F1: 0.12

Label: Stimulation  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.54  Recall: 0.07  F1: 0.13

Label: Stimulation  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.54  Recall: 0.07  F1: 0.13

Label: Hedonism  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.64  Recall: 0.13  F1: 0.21

Label: Hedonism  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.64  Recall: 0.13  F1: 0.21

Label: Achievement  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.94  Recall: 0.99  F1: 0.97
  Class 1 (positive)
    Precision: 0.58  Recall: 0.13  F1: 0.21

Label: Achievement  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.99  F1: 0.97
  Class 1 (positive)
    Precision: 0.58  Recall: 0.13  F1: 0.21

Label: Humility  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.33  Recall: 0.03  F1: 0.06

Label: Humility  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.33  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.09  F1: 0.15

Label: Benevolence: caring  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.09  F1: 0.15

Label: Benevolence: dependability  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.11  F1: 0.17

Label: Benevolence: dependability  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.11  F1: 0.17

Label: Universalism: concern  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.95  Recall: 1.00  F1: 0.97
  Class 1 (positive)
    Precision: 0.67  Recall: 0.02  F1: 0.04

Label: Universalism: concern  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 1.00  F1: 0.97
  Class 1 (positive)
    Precision: 0.67  Recall: 0.02  F1: 0.04

Label: Universalism: nature  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.77  Recall: 0.16  F1: 0.27

Label: Universalism: nature  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.77  Recall: 0.16  F1: 0.27

Label: Universalism: tolerance  |  best threshold = 0.10
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.04  F1: 0.06

Label: Universalism: tolerance  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.04  F1: 0.06

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 11 labels: 0.13155

Macro-average F1 (fixed threshold) across 11 labels: 0.13155
