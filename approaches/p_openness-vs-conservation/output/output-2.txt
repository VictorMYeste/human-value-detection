==========
==========
==========
===== Lex-LIWC =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-LIWC-15 (based on Presence = Baseline) =====
==========
----- Predicting Validation -----
2025-05-26 15:38:43,314 - INFO - Using device: cuda
2025-05-26 15:38:43,435 - INFO - Hierarchical run ➜ 8968 / 14904 sentences will be processed by the value model (threshold=0.5)
----- Predicting Test -----
2025-05-26 15:40:55,761 - INFO - Using device: cuda
2025-05-26 15:40:55,919 - INFO - Hierarchical run ➜ 8938 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.84
  Class 0 (negative)
    Precision: 0.94  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.23  F1: 0.29

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.36  F1: 0.33

Label: Conservation  |  best threshold = 0.12
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.74  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.83  F1: 0.85
  Class 1 (positive)
    Precision: 0.48  Recall: 0.58  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.41

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.84
  Class 0 (negative)
    Precision: 0.93  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.37  Recall: 0.21  F1: 0.27

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.30  Recall: 0.35  F1: 0.32

Label: Conservation  |  best threshold = 0.12
  Class 0 (negative)
    Precision: 0.91  Recall: 0.69  F1: 0.78
  Class 1 (positive)
    Precision: 0.38  Recall: 0.74  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.82  F1: 0.85
  Class 1 (positive)
    Precision: 0.46  Recall: 0.60  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.39

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
===== Lex-LIWC-15 (based on Presence = Lex-LIWC-22_LingFeat) =====
==========
----- Predicting Validation -----
2025-05-26 15:43:08,096 - INFO - Using device: cuda
2025-05-26 15:43:08,224 - INFO - Hierarchical run ➜ 8486 / 14904 sentences will be processed by the value model (threshold=0.5)
----- Predicting Test -----
2025-05-26 15:45:12,275 - INFO - Using device: cuda
2025-05-26 15:45:12,397 - INFO - Hierarchical run ➜ 8435 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.83
  Class 0 (negative)
    Precision: 0.94  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.22  F1: 0.29

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.94  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.34  F1: 0.33

Label: Conservation  |  best threshold = 0.11
  Class 0 (negative)
    Precision: 0.90  Recall: 0.71  F1: 0.80
  Class 1 (positive)
    Precision: 0.40  Recall: 0.72  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.87  Recall: 0.83  F1: 0.85
  Class 1 (positive)
    Precision: 0.48  Recall: 0.56  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.40

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.83
  Class 0 (negative)
    Precision: 0.94  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.21  F1: 0.28

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.94  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.34  F1: 0.32

Label: Conservation  |  best threshold = 0.11
  Class 0 (negative)
    Precision: 0.91  Recall: 0.71  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.72  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.83  F1: 0.86
  Class 1 (positive)
    Precision: 0.47  Recall: 0.58  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.39

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Lex-LIWC-15 (based on Presence = Lex-LIWC-22_LingFeat) =====
==========
----- Predicting Validation -----
2025-05-26 15:47:19,104 - INFO - Using device: cuda
2025-05-26 15:47:19,225 - INFO - Hierarchical run ➜ 11931 / 14904 sentences will be processed by the value model (threshold=0.1)
----- Predicting Test -----
2025-05-26 15:49:58,929 - INFO - Using device: cuda
2025-05-26 15:49:59,049 - INFO - Hierarchical run ➜ 11715 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.90  F1: 0.92
  Class 1 (positive)
    Precision: 0.27  Recall: 0.44  F1: 0.33

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.90  F1: 0.92
  Class 1 (positive)
    Precision: 0.27  Recall: 0.44  F1: 0.33

Label: Conservation  |  best threshold = 0.36
  Class 0 (negative)
    Precision: 0.90  Recall: 0.71  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.72  F1: 0.51

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.75  F1: 0.82
  Class 1 (positive)
    Precision: 0.42  Recall: 0.66  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.42

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.90  F1: 0.92
  Class 1 (positive)
    Precision: 0.27  Recall: 0.43  F1: 0.33

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.90  F1: 0.92
  Class 1 (positive)
    Precision: 0.27  Recall: 0.43  F1: 0.33

Label: Conservation  |  best threshold = 0.36
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.73  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.90  Recall: 0.75  F1: 0.82
  Class 1 (positive)
    Precision: 0.41  Recall: 0.68  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.42

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
===== Lex-LIWC-15 (based on Presence = Previous-Sentences-2-Lex-EmoLex) =====
==========
----- Predicting Validation -----
2025-05-26 15:52:40,104 - INFO - Using device: cuda
2025-05-26 15:52:40,257 - INFO - Hierarchical run ➜ 10303 / 14904 sentences will be processed by the value model (threshold=0.1)
----- Predicting Test -----
2025-05-26 15:55:03,125 - INFO - Using device: cuda
2025-05-26 15:55:03,276 - INFO - Hierarchical run ➜ 10203 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.40  F1: 0.33

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.40  F1: 0.33

Label: Conservation  |  best threshold = 0.20
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.73  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.80  F1: 0.84
  Class 1 (positive)
    Precision: 0.45  Recall: 0.60  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.43

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.39  F1: 0.33

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.39  F1: 0.33

Label: Conservation  |  best threshold = 0.20
  Class 0 (negative)
    Precision: 0.91  Recall: 0.69  F1: 0.78
  Class 1 (positive)
    Precision: 0.37  Recall: 0.73  F1: 0.49

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.80  F1: 0.84
  Class 1 (positive)
    Precision: 0.44  Recall: 0.62  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.41

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
===== Lex-LIWC-15 (based on Presence = Previous-Sentences-2-Lex-LIWC-22) =====
==========
----- Predicting Validation -----
2025-05-26 15:57:27,811 - INFO - Using device: cuda
2025-05-26 15:57:27,933 - INFO - Hierarchical run ➜ 10733 / 14904 sentences will be processed by the value model (threshold=0.1)
----- Predicting Test -----
2025-05-26 15:59:54,714 - INFO - Using device: cuda
2025-05-26 15:59:54,836 - INFO - Hierarchical run ➜ 10509 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.42  F1: 0.33

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.42  F1: 0.33

Label: Conservation  |  best threshold = 0.23
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.74  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.79  F1: 0.83
  Class 1 (positive)
    Precision: 0.44  Recall: 0.62  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.43

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.40  F1: 0.33

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.28  Recall: 0.40  F1: 0.33

Label: Conservation  |  best threshold = 0.23
  Class 0 (negative)
    Precision: 0.91  Recall: 0.69  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.74  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.90  Recall: 0.79  F1: 0.84
  Class 1 (positive)
    Precision: 0.43  Recall: 0.64  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.42

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
===== Lex-LIWC-15 (based on Presence = Previous-Sentences-2-Lex-eMFD) =====
==========
----- Predicting Validation -----
2025-05-26 16:02:23,170 - INFO - Using device: cuda
2025-05-26 16:02:23,292 - INFO - Hierarchical run ➜ 10081 / 14904 sentences will be processed by the value model (threshold=0.1)
----- Predicting Test -----
2025-05-26 16:04:44,893 - INFO - Using device: cuda
2025-05-26 16:04:45,015 - INFO - Hierarchical run ➜ 9937 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.88
  Class 0 (negative)
    Precision: 0.94  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.23  F1: 0.29

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.29  Recall: 0.41  F1: 0.34

Label: Conservation  |  best threshold = 0.20
  Class 0 (negative)
    Precision: 0.90  Recall: 0.71  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.72  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.80  F1: 0.84
  Class 1 (positive)
    Precision: 0.45  Recall: 0.59  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.40

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.88
  Class 0 (negative)
    Precision: 0.93  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.38  Recall: 0.21  F1: 0.27

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.29  Recall: 0.38  F1: 0.33

Label: Conservation  |  best threshold = 0.20
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.72  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.80  F1: 0.84
  Class 1 (positive)
    Precision: 0.44  Recall: 0.61  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.38

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
-----------------------------------------------------
==========
==========
==========
===== TD-NMF =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== TD-NMF (based on Presence = Baseline) =====
==========
----- Predicting Validation -----
2025-05-26 16:07:08,468 - INFO - Using device: cuda
2025-05-26 16:07:08,589 - INFO - Hierarchical run ➜ 8968 / 14904 sentences will be processed by the value model (threshold=0.5)
2025-05-26 16:07:13,686 - INFO - Using topic_feature_dim = 39
----- Predicting Test -----
2025-05-26 16:08:07,062 - INFO - Using device: cuda
2025-05-26 16:08:07,185 - INFO - Hierarchical run ➜ 8938 / 14569 sentences will be processed by the value model (threshold=0.5)
2025-05-26 16:08:11,568 - INFO - Using topic_feature_dim = 39
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.80
  Class 0 (negative)
    Precision: 0.94  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.21  F1: 0.28

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.95  F1: 0.94
  Class 1 (positive)
    Precision: 0.33  Recall: 0.32  F1: 0.33

Label: Conservation  |  best threshold = 0.15
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.74  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.82  F1: 0.85
  Class 1 (positive)
    Precision: 0.47  Recall: 0.59  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.40

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.80
  Class 0 (negative)
    Precision: 0.93  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.39  Recall: 0.20  F1: 0.27

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.94  F1: 0.94
  Class 1 (positive)
    Precision: 0.33  Recall: 0.32  F1: 0.32

Label: Conservation  |  best threshold = 0.15
  Class 0 (negative)
    Precision: 0.91  Recall: 0.68  F1: 0.78
  Class 1 (positive)
    Precision: 0.38  Recall: 0.75  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.81  F1: 0.85
  Class 1 (positive)
    Precision: 0.45  Recall: 0.62  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.38

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
===== TD-NMF (based on Presence = Lex-LIWC-22_LingFeat) =====
==========
----- Predicting Validation -----
2025-05-26 16:09:08,535 - INFO - Using device: cuda
2025-05-26 16:09:08,656 - INFO - Hierarchical run ➜ 8486 / 14904 sentences will be processed by the value model (threshold=0.5)
2025-05-26 16:09:13,764 - INFO - Using topic_feature_dim = 39
----- Predicting Test -----
2025-05-26 16:10:05,385 - INFO - Using device: cuda
2025-05-26 16:10:05,505 - INFO - Hierarchical run ➜ 8435 / 14569 sentences will be processed by the value model (threshold=0.5)
2025-05-26 16:10:09,867 - INFO - Using topic_feature_dim = 39
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.79
  Class 0 (negative)
    Precision: 0.94  Recall: 0.98  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.20  F1: 0.27

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.31  F1: 0.32

Label: Conservation  |  best threshold = 0.13
  Class 0 (negative)
    Precision: 0.90  Recall: 0.71  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.72  F1: 0.51

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.83  F1: 0.85
  Class 1 (positive)
    Precision: 0.47  Recall: 0.57  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.39

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.79
  Class 0 (negative)
    Precision: 0.93  Recall: 0.97  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.21  F1: 0.28

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.31  F1: 0.32

Label: Conservation  |  best threshold = 0.13
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.73  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.83  F1: 0.86
  Class 1 (positive)
    Precision: 0.47  Recall: 0.59  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.39

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== TD-NMF (based on Presence = Lex-LIWC-22_LingFeat) =====
==========
----- Predicting Validation -----
2025-05-26 16:11:05,237 - INFO - Using device: cuda
2025-05-26 16:11:05,358 - INFO - Hierarchical run ➜ 11931 / 14904 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:11:10,439 - INFO - Using topic_feature_dim = 39
----- Predicting Test -----
2025-05-26 16:12:14,944 - INFO - Using device: cuda
2025-05-26 16:12:15,064 - INFO - Hierarchical run ➜ 11715 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:12:19,352 - INFO - Using topic_feature_dim = 39
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.29  Recall: 0.41  F1: 0.34

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.29  Recall: 0.41  F1: 0.34

Label: Conservation  |  best threshold = 0.40
  Class 0 (negative)
    Precision: 0.90  Recall: 0.71  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.72  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.74  F1: 0.81
  Class 1 (positive)
    Precision: 0.42  Recall: 0.67  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.43

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.30  Recall: 0.41  F1: 0.34

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.92  F1: 0.93
  Class 1 (positive)
    Precision: 0.30  Recall: 0.41  F1: 0.34

Label: Conservation  |  best threshold = 0.40
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.39  Recall: 0.74  F1: 0.51

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.90  Recall: 0.74  F1: 0.81
  Class 1 (positive)
    Precision: 0.40  Recall: 0.69  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.42

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
==========
===== TD-NMF (based on Presence = Previous-Sentences-2-Lex-EmoLex) =====
==========
----- Predicting Validation -----
2025-05-26 16:13:27,141 - INFO - Using device: cuda
2025-05-26 16:13:27,262 - INFO - Hierarchical run ➜ 10303 / 14904 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:13:32,379 - INFO - Using topic_feature_dim = 39
----- Predicting Test -----
2025-05-26 16:14:30,941 - INFO - Using device: cuda
2025-05-26 16:14:31,062 - INFO - Hierarchical run ➜ 10203 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:14:35,446 - INFO - Using topic_feature_dim = 39
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.88
  Class 0 (negative)
    Precision: 0.93  Recall: 0.98  F1: 0.96
  Class 1 (positive)
    Precision: 0.40  Recall: 0.18  F1: 0.25

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.30  Recall: 0.37  F1: 0.33

Label: Conservation  |  best threshold = 0.25
  Class 0 (negative)
    Precision: 0.90  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.73  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.79  F1: 0.83
  Class 1 (positive)
    Precision: 0.44  Recall: 0.62  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.38

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.88
  Class 0 (negative)
    Precision: 0.93  Recall: 0.98  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.18  F1: 0.25

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.36  F1: 0.33

Label: Conservation  |  best threshold = 0.25
  Class 0 (negative)
    Precision: 0.91  Recall: 0.69  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.73  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.90  Recall: 0.79  F1: 0.84
  Class 1 (positive)
    Precision: 0.43  Recall: 0.64  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.37

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
==========
===== TD-NMF (based on Presence = Previous-Sentences-2-Lex-LIWC-22) =====
==========
----- Predicting Validation -----
2025-05-26 16:15:37,164 - INFO - Using device: cuda
2025-05-26 16:15:37,285 - INFO - Hierarchical run ➜ 10733 / 14904 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:15:42,391 - INFO - Using topic_feature_dim = 39
----- Predicting Test -----
2025-05-26 16:16:42,744 - INFO - Using device: cuda
2025-05-26 16:16:42,865 - INFO - Hierarchical run ➜ 10509 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:16:47,381 - INFO - Using topic_feature_dim = 39
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.30  Recall: 0.38  F1: 0.34

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.30  Recall: 0.38  F1: 0.34

Label: Conservation  |  best threshold = 0.28
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.73  F1: 0.52

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.78  F1: 0.83
  Class 1 (positive)
    Precision: 0.43  Recall: 0.63  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.43

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.37  F1: 0.34

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.37  F1: 0.34

Label: Conservation  |  best threshold = 0.28
  Class 0 (negative)
    Precision: 0.91  Recall: 0.69  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.74  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.90  Recall: 0.78  F1: 0.83
  Class 1 (positive)
    Precision: 0.43  Recall: 0.65  F1: 0.52

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.42

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
==========
===== TD-NMF (based on Presence = Previous-Sentences-2-Lex-eMFD) =====
==========
----- Predicting Validation -----
2025-05-26 16:17:50,264 - INFO - Using device: cuda
2025-05-26 16:17:50,385 - INFO - Hierarchical run ➜ 10081 / 14904 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:17:55,500 - INFO - Using topic_feature_dim = 39
----- Predicting Test -----
2025-05-26 16:18:53,729 - INFO - Using device: cuda
2025-05-26 16:18:53,849 - INFO - Hierarchical run ➜ 9937 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-26 16:18:58,227 - INFO - Using topic_feature_dim = 39
----- Extracting per-label thresholds from Validation -----

Label: Openness to Change  |  best threshold = 0.87
  Class 0 (negative)
    Precision: 0.94  Recall: 0.98  F1: 0.96
  Class 1 (positive)
    Precision: 0.41  Recall: 0.19  F1: 0.26

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.37  F1: 0.34

Label: Conservation  |  best threshold = 0.25
  Class 0 (negative)
    Precision: 0.90  Recall: 0.71  F1: 0.79
  Class 1 (positive)
    Precision: 0.40  Recall: 0.72  F1: 0.51

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.88  Recall: 0.79  F1: 0.83
  Class 1 (positive)
    Precision: 0.44  Recall: 0.61  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.39

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.42
----- Evaluating Test -----

Label: Openness to Change  |  best threshold = 0.87
  Class 0 (negative)
    Precision: 0.93  Recall: 0.98  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.19  F1: 0.26

Label: Openness to Change  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.94  Recall: 0.93  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.36  F1: 0.34

Label: Conservation  |  best threshold = 0.25
  Class 0 (negative)
    Precision: 0.91  Recall: 0.70  F1: 0.79
  Class 1 (positive)
    Precision: 0.38  Recall: 0.72  F1: 0.50

Label: Conservation  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.89  Recall: 0.79  F1: 0.84
  Class 1 (positive)
    Precision: 0.44  Recall: 0.63  F1: 0.51

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 2 labels: 0.38

Macro-average F1 (fixed 0.50 threshold) across 2 labels: 0.43
