2025-02-25 16:31:42,798 - INFO - PyTorch version 2.6.0+cu118 available.
2025-02-25 16:31:42,798 - INFO - PyTorch version 2.6.0+cu118 available.
2025-02-25 16:31:59,341 - INFO - Setting random seed to 42
2025-02-25 16:31:59,360 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-02-25 16:31:59,542 - INFO - Loading lexicon embeddings for: No lexicon used
2025-02-25 16:31:59,542 - INFO - Preparing datasets for training and validation
2025-02-25 16:32:01,290 - INFO - Adding Previous Sentences Labels features
2025-02-25 16:32:02,347 - INFO - Adding Previous Sentences Labels features
2025-02-25 16:32:02,347 - INFO - Skipping previous label features in validation (no model available).
2025-02-25 16:32:02,420 - INFO - Arguments validated successfully.
2025-02-25 16:32:02,423 - INFO - Previous sentences or augmented data detected. Adjusting batch size: 4 -> 2 and gradient accumulation steps: 4 -> 8
2025-02-25 16:32:02,423 - INFO - Clearing old checkpoints in models/checkpoints
2025-02-25 16:32:02,886 - INFO - Using CUDA for training.
2025-02-25 16:32:06,637 - ERROR - An error occurred: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
Traceback (most recent call last):
  File "/home/vicyesmo/human-value-detection/approaches/presence/main.py", line 126, in <module>
    main()
  File "/home/vicyesmo/human-value-detection/approaches/presence/main.py", line 99, in main
    run_training(
  File "/home/vicyesmo/human-value-detection/core/runner.py", line 79, in run_training
    trainer = train(
  File "/home/vicyesmo/human-value-detection/core/training.py", line 172, in train
    model = move_to_device(model)
  File "/home/vicyesmo/human-value-detection/core/models.py", line 40, in move_to_device
    return model.to('cuda')
  File "/home/vicyesmo/.conda/envs/hvd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1343, in to
    return self._apply(convert)
  File "/home/vicyesmo/.conda/envs/hvd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/vicyesmo/.conda/envs/hvd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/vicyesmo/.conda/envs/hvd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 903, in _apply
    module._apply(fn)
  File "/home/vicyesmo/.conda/envs/hvd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 930, in _apply
    param_applied = fn(param)
  File "/home/vicyesmo/.conda/envs/hvd/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1329, in convert
    return t.to(
RuntimeError: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

