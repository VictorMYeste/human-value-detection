2025-04-18 21:54:02,319 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-18 21:54:02,319 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-18 21:54:09,375 - INFO - Setting random seed to 42
2025-04-18 21:54:09,376 - INFO - Running training for labels: ['Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility']
2025-04-18 21:54:09,376 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-04-18 21:54:09,790 - INFO - Loading lexicon embeddings for: No lexicon used
2025-04-18 21:54:09,790 - INFO - Preparing datasets for training and validation
2025-04-18 21:54:24,768 - INFO - Arguments validated successfully.
2025-04-18 21:54:24,771 - INFO - Previous sentences or augmented data detected. Adjusting batch size: 4 -> 2 and gradient accumulation steps: 4 -> 8
2025-04-18 21:54:24,772 - INFO - Clearing old checkpoints in models/checkpoints
2025-04-18 21:54:26,396 - INFO - Using CUDA for training.
2025-04-18 21:54:27,516 - INFO - TRAINING
2025-04-18 21:54:27,516 - INFO - ========
2025-04-18 21:54:27,516 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: None
Filter labels: ['Self-Protection Anxiety-Avoidance']
Batch size: 2
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 8
Early stopping patience: 4
Multilayer: No
Previous sentences used: No
Using lexicon: No
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 0
Using data augmentation with paraphrasing: Yes
Adding topic detection features: No
Applying token pruning: No

2025-04-18 21:54:27,519 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.3031, 'grad_norm': 0.7037065625190735, 'learning_rate': 1.9065420560747666e-05, 'epoch': 0.47}
{'loss': 0.2713, 'grad_norm': 1.0906085968017578, 'learning_rate': 1.8130841121495328e-05, 'epoch': 0.93}
{'eval_loss': 0.2332991510629654, 'eval_f1-score': {'Achievement': 0.38, 'Power: dominance': 0.19, 'Power: resources': 0.28, 'Face': 0.01, 'Security: personal': 0.31, 'Security: societal': 0.55, 'Tradition': 0.39, 'Conformity: rules': 0.54, 'Conformity: interpersonal': 0, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.26, 'eval_runtime': 148.9414, 'eval_samples_per_second': 35.437, 'eval_steps_per_second': 8.863, 'epoch': 1.0}
2025-04-18 22:54:20,766 - INFO - Skipping evaluation for warm-up phase (epoch 0).
{'loss': 0.2459, 'grad_norm': 1.1529462337493896, 'learning_rate': 1.7196261682242992e-05, 'epoch': 1.4}
{'loss': 0.2313, 'grad_norm': 1.1254280805587769, 'learning_rate': 1.6261682242990654e-05, 'epoch': 1.87}
{'eval_loss': 0.23878833651542664, 'eval_f1-score': {'Achievement': 0.51, 'Power: dominance': 0.35, 'Power: resources': 0.45, 'Face': 0.12, 'Security: personal': 0.4, 'Security: societal': 0.48, 'Tradition': 0.4, 'Conformity: rules': 0.48, 'Conformity: interpersonal': 0, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.32, 'eval_runtime': 148.8653, 'eval_samples_per_second': 35.455, 'eval_steps_per_second': 8.867, 'epoch': 2.0}
2025-04-18 23:54:31,474 - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'loss': 0.1978, 'grad_norm': 1.502689003944397, 'learning_rate': 1.5327102803738318e-05, 'epoch': 2.33}
{'loss': 0.1788, 'grad_norm': 2.3596675395965576, 'learning_rate': 1.4392523364485981e-05, 'epoch': 2.8}
{'eval_loss': 0.264041930437088, 'eval_f1-score': {'Achievement': 0.45, 'Power: dominance': 0.32, 'Power: resources': 0.44, 'Face': 0.3, 'Security: personal': 0.42, 'Security: societal': 0.53, 'Tradition': 0.46, 'Conformity: rules': 0.46, 'Conformity: interpersonal': 0.01, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.34, 'eval_runtime': 149.2645, 'eval_samples_per_second': 35.36, 'eval_steps_per_second': 8.843, 'epoch': 3.0}
{'loss': 0.1517, 'grad_norm': 2.3122668266296387, 'learning_rate': 1.3457943925233646e-05, 'epoch': 3.27}
{'loss': 0.1292, 'grad_norm': 2.5102455615997314, 'learning_rate': 1.2523364485981309e-05, 'epoch': 3.74}
{'eval_loss': 0.30980655550956726, 'eval_f1-score': {'Achievement': 0.41, 'Power: dominance': 0.4, 'Power: resources': 0.37, 'Face': 0.3, 'Security: personal': 0.42, 'Security: societal': 0.52, 'Tradition': 0.46, 'Conformity: rules': 0.51, 'Conformity: interpersonal': 0.08, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.35, 'eval_runtime': 149.2925, 'eval_samples_per_second': 35.353, 'eval_steps_per_second': 8.842, 'epoch': 4.0}
{'loss': 0.1134, 'grad_norm': 1.9087512493133545, 'learning_rate': 1.1588785046728972e-05, 'epoch': 4.2}
{'loss': 0.0917, 'grad_norm': 2.4346189498901367, 'learning_rate': 1.0654205607476635e-05, 'epoch': 4.67}
{'eval_loss': 0.35151633620262146, 'eval_f1-score': {'Achievement': 0.45, 'Power: dominance': 0.36, 'Power: resources': 0.43, 'Face': 0.31, 'Security: personal': 0.41, 'Security: societal': 0.51, 'Tradition': 0.49, 'Conformity: rules': 0.5, 'Conformity: interpersonal': 0.06, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.35, 'eval_runtime': 149.9721, 'eval_samples_per_second': 35.193, 'eval_steps_per_second': 8.802, 'epoch': 5.0}
{'loss': 0.0822, 'grad_norm': 1.8715749979019165, 'learning_rate': 9.7196261682243e-06, 'epoch': 5.14}
{'loss': 0.0639, 'grad_norm': 2.887141227722168, 'learning_rate': 8.785046728971963e-06, 'epoch': 5.6}
{'eval_loss': 0.3939284384250641, 'eval_f1-score': {'Achievement': 0.44, 'Power: dominance': 0.38, 'Power: resources': 0.42, 'Face': 0.29, 'Security: personal': 0.42, 'Security: societal': 0.46, 'Tradition': 0.5, 'Conformity: rules': 0.53, 'Conformity: interpersonal': 0.07, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.35, 'eval_runtime': 150.2999, 'eval_samples_per_second': 35.116, 'eval_steps_per_second': 8.782, 'epoch': 6.0}
{'loss': 0.062, 'grad_norm': 1.091264009475708, 'learning_rate': 7.850467289719627e-06, 'epoch': 6.07}
{'loss': 0.0473, 'grad_norm': 2.7528481483459473, 'learning_rate': 6.91588785046729e-06, 'epoch': 6.54}
{'eval_loss': 0.42439356446266174, 'eval_f1-score': {'Achievement': 0.44, 'Power: dominance': 0.36, 'Power: resources': 0.43, 'Face': 0.29, 'Security: personal': 0.37, 'Security: societal': 0.48, 'Tradition': 0.47, 'Conformity: rules': 0.52, 'Conformity: interpersonal': 0.08, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.34, 'eval_runtime': 149.3131, 'eval_samples_per_second': 35.349, 'eval_steps_per_second': 8.84, 'epoch': 7.0}
{'loss': 0.0439, 'grad_norm': 1.8615409135818481, 'learning_rate': 5.981308411214953e-06, 'epoch': 7.0}
{'loss': 0.0343, 'grad_norm': 2.429954767227173, 'learning_rate': 5.046728971962617e-06, 'epoch': 7.47}
{'loss': 0.0344, 'grad_norm': 1.5449367761611938, 'learning_rate': 4.112149532710281e-06, 'epoch': 7.94}
{'eval_loss': 0.4547083079814911, 'eval_f1-score': {'Achievement': 0.46, 'Power: dominance': 0.39, 'Power: resources': 0.36, 'Face': 0.3, 'Security: personal': 0.39, 'Security: societal': 0.48, 'Tradition': 0.47, 'Conformity: rules': 0.49, 'Conformity: interpersonal': 0.09, 'Humility': 0}, 'eval_macro-avg-f1-score': 0.34, 'eval_runtime': 149.6938, 'eval_samples_per_second': 35.259, 'eval_steps_per_second': 8.818, 'epoch': 8.0}
{'train_runtime': 28988.1306, 'train_samples_per_second': 11.821, 'train_steps_per_second': 0.369, 'train_loss': 0.13348986343587727, 'epoch': 8.0}
2025-04-19 05:57:36,128 - INFO - 

VALIDATION
2025-04-19 05:57:36,128 - INFO - ==========
2025-04-19 06:00:05,352 - INFO - Achievement: 0.41
2025-04-19 06:00:05,352 - INFO - Power: dominance: 0.40
2025-04-19 06:00:05,352 - INFO - Power: resources: 0.37
2025-04-19 06:00:05,352 - INFO - Face: 0.30
2025-04-19 06:00:05,352 - INFO - Security: personal: 0.42
2025-04-19 06:00:05,352 - INFO - Security: societal: 0.52
2025-04-19 06:00:05,352 - INFO - Tradition: 0.46
2025-04-19 06:00:05,352 - INFO - Conformity: rules: 0.51
2025-04-19 06:00:05,352 - INFO - Conformity: interpersonal: 0.08
2025-04-19 06:00:05,352 - INFO - Humility: 0.00
2025-04-19 06:00:05,352 - INFO - Macro average: 0.35
2025-04-19 06:00:05,580 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
