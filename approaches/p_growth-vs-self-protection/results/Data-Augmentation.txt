2025-04-01 18:04:15,934 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-01 18:04:15,935 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-01 18:04:22,428 - INFO - Setting random seed to 42
2025-04-01 18:04:22,429 - INFO - Running training for labels: ['Growth Anxiety-Free', 'Self-Protection Anxiety-Avoidance']
2025-04-01 18:04:22,429 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-04-01 18:04:22,640 - INFO - Loading lexicon embeddings for: No lexicon used
2025-04-01 18:04:22,641 - INFO - Preparing datasets for training and validation
2025-04-01 18:04:43,546 - INFO - Arguments validated successfully.
2025-04-01 18:04:43,550 - INFO - Previous sentences or augmented data detected. Adjusting batch size: 4 -> 2 and gradient accumulation steps: 4 -> 8
2025-04-01 18:04:43,550 - INFO - Clearing old checkpoints in models/checkpoints
2025-04-01 18:04:44,632 - INFO - Using CUDA for training.
2025-04-01 18:04:45,806 - INFO - TRAINING
2025-04-01 18:04:45,807 - INFO - ========
2025-04-01 18:04:45,807 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: None
Filter labels: ['Presence']
Batch size: 2
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 8
Early stopping patience: 4
Multilayer: No
Previous sentences used: No
Using lexicon: No
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 0
Using data augmentation with paraphrasing: Yes
Adding topic detection features: No
Applying token pruning: No

2025-04-01 18:04:45,809 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.6501, 'grad_norm': 2.5092101097106934, 'learning_rate': 1.9361022364217256e-05, 'epoch': 0.32}
{'loss': 0.6193, 'grad_norm': 2.6903457641601562, 'learning_rate': 1.8722044728434506e-05, 'epoch': 0.64}
{'loss': 0.608, 'grad_norm': 2.0651988983154297, 'learning_rate': 1.808306709265176e-05, 'epoch': 0.96}
{'eval_loss': 0.5470837950706482, 'eval_f1-score': {'Growth Anxiety-Free': 0.7, 'Self-Protection Anxiety-Avoidance': 0.83}, 'eval_macro-avg-f1-score': 0.76, 'eval_runtime': 165.6445, 'eval_samples_per_second': 45.881, 'eval_steps_per_second': 11.47, 'epoch': 1.0}
2025-04-01 19:19:48,325 - INFO - Skipping evaluation for warm-up phase (epoch 0).
{'loss': 0.5379, 'grad_norm': 5.835049629211426, 'learning_rate': 1.744408945686901e-05, 'epoch': 1.28}
{'loss': 0.5072, 'grad_norm': 3.969388723373413, 'learning_rate': 1.6805111821086264e-05, 'epoch': 1.6}
{'loss': 0.4872, 'grad_norm': 6.368212699890137, 'learning_rate': 1.6166134185303515e-05, 'epoch': 1.92}
{'eval_loss': 0.601716160774231, 'eval_f1-score': {'Growth Anxiety-Free': 0.65, 'Self-Protection Anxiety-Avoidance': 0.81}, 'eval_macro-avg-f1-score': 0.73, 'eval_runtime': 163.764, 'eval_samples_per_second': 46.408, 'eval_steps_per_second': 11.602, 'epoch': 2.0}
2025-04-01 20:34:54,898 - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'loss': 0.3947, 'grad_norm': 6.542665004730225, 'learning_rate': 1.552715654952077e-05, 'epoch': 2.24}
{'loss': 0.3509, 'grad_norm': 7.350919723510742, 'learning_rate': 1.488817891373802e-05, 'epoch': 2.56}
{'loss': 0.3453, 'grad_norm': 9.35551929473877, 'learning_rate': 1.4249201277955273e-05, 'epoch': 2.87}
{'eval_loss': 0.7847453355789185, 'eval_f1-score': {'Growth Anxiety-Free': 0.64, 'Self-Protection Anxiety-Avoidance': 0.8}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 164.4975, 'eval_samples_per_second': 46.201, 'eval_steps_per_second': 11.55, 'epoch': 3.0}
{'loss': 0.279, 'grad_norm': 4.246623992919922, 'learning_rate': 1.3610223642172523e-05, 'epoch': 3.19}
{'loss': 0.2374, 'grad_norm': 6.509618759155273, 'learning_rate': 1.2971246006389777e-05, 'epoch': 3.51}
{'loss': 0.2306, 'grad_norm': 9.92365550994873, 'learning_rate': 1.233226837060703e-05, 'epoch': 3.83}
{'eval_loss': 1.0608205795288086, 'eval_f1-score': {'Growth Anxiety-Free': 0.65, 'Self-Protection Anxiety-Avoidance': 0.79}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 164.6093, 'eval_samples_per_second': 46.17, 'eval_steps_per_second': 11.542, 'epoch': 4.0}
{'loss': 0.1986, 'grad_norm': 8.815481185913086, 'learning_rate': 1.1693290734824283e-05, 'epoch': 4.15}
{'loss': 0.1685, 'grad_norm': 8.1741361618042, 'learning_rate': 1.1054313099041534e-05, 'epoch': 4.47}
{'loss': 0.1704, 'grad_norm': 8.102246284484863, 'learning_rate': 1.0415335463258786e-05, 'epoch': 4.79}
{'eval_loss': 1.201012372970581, 'eval_f1-score': {'Growth Anxiety-Free': 0.63, 'Self-Protection Anxiety-Avoidance': 0.8}, 'eval_macro-avg-f1-score': 0.72, 'eval_runtime': 162.129, 'eval_samples_per_second': 46.876, 'eval_steps_per_second': 11.719, 'epoch': 5.0}
{'loss': 0.1501, 'grad_norm': 13.145373344421387, 'learning_rate': 9.77635782747604e-06, 'epoch': 5.11}
{'loss': 0.119, 'grad_norm': 7.4136481285095215, 'learning_rate': 9.137380191693292e-06, 'epoch': 5.43}
{'loss': 0.1201, 'grad_norm': 8.742058753967285, 'learning_rate': 8.498402555910544e-06, 'epoch': 5.75}
{'eval_loss': 1.3208706378936768, 'eval_f1-score': {'Growth Anxiety-Free': 0.65, 'Self-Protection Anxiety-Avoidance': 0.8}, 'eval_macro-avg-f1-score': 0.73, 'eval_runtime': 159.4868, 'eval_samples_per_second': 47.653, 'eval_steps_per_second': 11.913, 'epoch': 6.0}
{'loss': 0.1179, 'grad_norm': 11.380279541015625, 'learning_rate': 7.859424920127796e-06, 'epoch': 6.07}
{'loss': 0.0896, 'grad_norm': 9.803840637207031, 'learning_rate': 7.220447284345049e-06, 'epoch': 6.39}
{'loss': 0.0856, 'grad_norm': 10.440422058105469, 'learning_rate': 6.581469648562301e-06, 'epoch': 6.71}
{'eval_loss': 1.5675129890441895, 'eval_f1-score': {'Growth Anxiety-Free': 0.64, 'Self-Protection Anxiety-Avoidance': 0.81}, 'eval_macro-avg-f1-score': 0.73, 'eval_runtime': 163.5561, 'eval_samples_per_second': 46.467, 'eval_steps_per_second': 11.617, 'epoch': 7.0}
{'loss': 0.0855, 'grad_norm': 6.704564571380615, 'learning_rate': 5.942492012779553e-06, 'epoch': 7.03}
{'loss': 0.0675, 'grad_norm': 14.2486572265625, 'learning_rate': 5.303514376996806e-06, 'epoch': 7.35}
{'loss': 0.0672, 'grad_norm': 6.693056583404541, 'learning_rate': 4.664536741214058e-06, 'epoch': 7.67}
{'loss': 0.0644, 'grad_norm': 3.1368157863616943, 'learning_rate': 4.02555910543131e-06, 'epoch': 7.99}
{'eval_loss': 2.0474941730499268, 'eval_f1-score': {'Growth Anxiety-Free': 0.65, 'Self-Protection Anxiety-Avoidance': 0.81}, 'eval_macro-avg-f1-score': 0.73, 'eval_runtime': 162.045, 'eval_samples_per_second': 46.901, 'eval_steps_per_second': 11.725, 'epoch': 8.0}
{'loss': 0.0511, 'grad_norm': 0.2941672205924988, 'learning_rate': 3.386581469648563e-06, 'epoch': 8.3}
{'loss': 0.0518, 'grad_norm': 1.7242519855499268, 'learning_rate': 2.747603833865815e-06, 'epoch': 8.62}
{'loss': 0.0516, 'grad_norm': 8.547513008117676, 'learning_rate': 2.1086261980830672e-06, 'epoch': 8.94}
{'eval_loss': 2.2561569213867188, 'eval_f1-score': {'Growth Anxiety-Free': 0.66, 'Self-Protection Anxiety-Avoidance': 0.81}, 'eval_macro-avg-f1-score': 0.74, 'eval_runtime': 160.045, 'eval_samples_per_second': 47.487, 'eval_steps_per_second': 11.872, 'epoch': 9.0}
{'loss': 0.0409, 'grad_norm': 14.533851623535156, 'learning_rate': 1.4696485623003196e-06, 'epoch': 9.26}
{'loss': 0.039, 'grad_norm': 9.4247465133667, 'learning_rate': 8.306709265175719e-07, 'epoch': 9.58}
{'loss': 0.0406, 'grad_norm': 10.051339149475098, 'learning_rate': 1.9169329073482428e-07, 'epoch': 9.9}
{'eval_loss': 2.3556621074676514, 'eval_f1-score': {'Growth Anxiety-Free': 0.65, 'Self-Protection Anxiety-Avoidance': 0.81}, 'eval_macro-avg-f1-score': 0.73, 'eval_runtime': 163.1077, 'eval_samples_per_second': 46.595, 'eval_steps_per_second': 11.649, 'epoch': 10.0}
{'train_runtime': 45233.7596, 'train_samples_per_second': 11.074, 'train_steps_per_second': 0.346, 'train_loss': 0.2248494325887662, 'epoch': 10.0}
2025-04-02 06:38:39,992 - INFO - 

VALIDATION
2025-04-02 06:38:39,992 - INFO - ==========
2025-04-02 06:41:23,760 - INFO - Growth Anxiety-Free: 0.66
2025-04-02 06:41:23,760 - INFO - Self-Protection Anxiety-Avoidance: 0.81
2025-04-02 06:41:23,760 - INFO - Macro average: 0.74
2025-04-02 06:41:24,174 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
