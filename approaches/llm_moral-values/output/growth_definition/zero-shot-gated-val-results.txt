
Label: Self-direction: thought  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.07  Recall: 0.11  F1: 0.08

Label: Self-direction: thought  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.07  Recall: 0.11  F1: 0.08

Label: Self-direction: action  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.98  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.12  Recall: 0.31  F1: 0.17

Label: Self-direction: action  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.12  Recall: 0.31  F1: 0.17

Label: Stimulation  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.98  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.12  Recall: 0.23  F1: 0.16

Label: Stimulation  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.12  Recall: 0.23  F1: 0.16

Label: Hedonism  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.23  F1: 0.23

Label: Hedonism  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.23  F1: 0.23

Label: Achievement  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.96  Recall: 0.81  F1: 0.88
  Class 1 (positive)
    Precision: 0.16  Recall: 0.51  F1: 0.24

Label: Achievement  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.81  F1: 0.88
  Class 1 (positive)
    Precision: 0.16  Recall: 0.51  F1: 0.24

Label: Humility  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.08  Recall: 0.09  F1: 0.08

Label: Humility  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.08  Recall: 0.09  F1: 0.08

Label: Benevolence: caring  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.99  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.12  Recall: 0.50  F1: 0.20

Label: Benevolence: caring  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.12  Recall: 0.50  F1: 0.20

Label: Benevolence: dependability  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.12  Recall: 0.17  F1: 0.14

Label: Benevolence: dependability  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.12  Recall: 0.17  F1: 0.14

Label: Universalism: concern  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.98  Recall: 0.82  F1: 0.89
  Class 1 (positive)
    Precision: 0.13  Recall: 0.59  F1: 0.22

Label: Universalism: concern  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.82  F1: 0.89
  Class 1 (positive)
    Precision: 0.13  Recall: 0.59  F1: 0.22

Label: Universalism: nature  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.39  Recall: 0.76  F1: 0.51

Label: Universalism: nature  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.39  Recall: 0.76  F1: 0.51

Label: Universalism: tolerance  |  best threshold = 0.50
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.22  F1: 0.16

Label: Universalism: tolerance  |  Fixed 0.5 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.22  F1: 0.16

=== SUMMARY =================================================

Macro-average F1 (tuned thresholds) across 11 labels: 0.19883

Macro-average F1 (fixed threshold) across 11 labels: 0.19883
