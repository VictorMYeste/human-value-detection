==========
==========
==========
===== Baseline =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Baseline (based on Self-Transcendence = Baseline) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.20  Recall: 0.07  F1: 0.10

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.21  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.20  F1: 0.22

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.40  Recall: 0.39  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.62  F1: 0.58

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.20  Recall: 0.18  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.28768
==========
===== Baseline (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.30  Recall: 0.10  F1: 0.15

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.19  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.27  Recall: 0.20  F1: 0.23

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.43  Recall: 0.39  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.57  Recall: 0.59  F1: 0.58

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.19  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29836
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Self-Transcendence = Lex-WorryWords) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.11  Recall: 0.10  F1: 0.10

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.26  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.34  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.48  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.74  F1: 0.59

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.26  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.30067
==========
===== Baseline (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.14  Recall: 0.10  F1: 0.12

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.25  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.35  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.47  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.48  Recall: 0.70  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.18  Recall: 0.24  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29862
==========
===== Baseline (based on Self-Transcendence = TD-BERTopic) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.12  Recall: 0.10  F1: 0.11

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.25  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.34  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.48  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.47  Recall: 0.73  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.27  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29896
-----------------------------------------------------
==========
==========
==========
===== Lex-Schwartz =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-Schwartz (based on Self-Transcendence = Baseline) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.25  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.22  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.18  F1: 0.22

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.43  Recall: 0.39  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.61  F1: 0.58

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.20  Recall: 0.25  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.28571
==========
===== Lex-Schwartz (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.29  Recall: 0.07  F1: 0.11

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.19  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.18  F1: 0.22

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.98  F1: 0.97
  Class 1 (positive)
    Precision: 0.46  Recall: 0.38  F1: 0.42

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.57  Recall: 0.58  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.25  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29398
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Lex-Schwartz (based on Self-Transcendence = Lex-WorryWords) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.09  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.28  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.30  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.36  Recall: 0.46  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.50  Recall: 0.72  F1: 0.59

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.18  Recall: 0.33  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.30137
==========
===== Lex-Schwartz (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.11  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.27  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.37  Recall: 0.46  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.68  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.17  Recall: 0.30  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29818
==========
===== Lex-Schwartz (based on Self-Transcendence = TD-BERTopic) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.11  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.27  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.29  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.36  Recall: 0.47  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.47  Recall: 0.71  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.37  F1: 0.25

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.30017
-----------------------------------------------------
==========
==========
==========
===== Lex-EmoLex =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-EmoLex (based on Self-Transcendence = Baseline) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.25  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.20  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.18  F1: 0.22

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.42  Recall: 0.39  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.61  F1: 0.58

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.23  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.28258
==========
===== Lex-EmoLex (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.29  Recall: 0.07  F1: 0.11

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.17  F1: 0.20

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.18  F1: 0.23

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.98  F1: 0.97
  Class 1 (positive)
    Precision: 0.45  Recall: 0.38  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.57  Recall: 0.58  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.20  Recall: 0.24  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29124
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Lex-EmoLex (based on Self-Transcendence = Lex-WorryWords) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.09  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.26  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.46  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.72  F1: 0.59

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.17  Recall: 0.32  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29855
==========
===== Lex-EmoLex (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.11  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.26  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.32  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.36  Recall: 0.46  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.68  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.16  Recall: 0.29  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29653
==========
===== Lex-EmoLex (based on Self-Transcendence = TD-BERTopic) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.11  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.25  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.30  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.36  Recall: 0.47  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.47  Recall: 0.71  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.18  Recall: 0.36  F1: 0.24

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29850
-----------------------------------------------------
==========
==========
==========
===== Lex-MFD =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-MFD (based on Self-Transcendence = Baseline) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.28  Recall: 0.21  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.31  Recall: 0.15  F1: 0.20

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.40  Recall: 0.42  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.60  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.19  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.27193
==========
===== Lex-MFD (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 1.00  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.26  Recall: 0.17  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.34  Recall: 0.15  F1: 0.21

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.44  Recall: 0.41  F1: 0.42

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.57  Recall: 0.57  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.27  Recall: 0.20  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.28415
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Lex-MFD (based on Self-Transcendence = Lex-WorryWords) =====
==========

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.17  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.20  Recall: 0.26  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.31  Recall: 0.24  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.50  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.50  Recall: 0.73  F1: 0.59

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.23  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29554
==========
===== Lex-MFD (based on Self-Transcendence = Lex-MFD-20) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.25  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.20  Recall: 0.25  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.31  Recall: 0.25  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.50  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.69  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.23  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29347
==========
===== Lex-MFD (based on Self-Transcendence = TD-BERTopic) =====
==========
----- Evaluating Test -----

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.25  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.25  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.31  Recall: 0.24  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.51  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.47  Recall: 0.71  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.26  F1: 0.25

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 6 labels: 0.29379
