2025-05-02 13:19:47,507 - INFO - PyTorch version 2.6.0+cu118 available.
2025-05-02 13:19:47,507 - INFO - PyTorch version 2.6.0+cu118 available.
2025-05-02 13:19:58,430 - INFO - Setting random seed to 42
2025-05-02 13:19:58,431 - INFO - Running training for labels: ['Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance']
2025-05-02 13:19:58,431 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-05-02 13:19:58,598 - INFO - Loading lexicon embeddings for: EmoLex
2025-05-02 13:19:58,697 - INFO - Preparing datasets for training and validation
2025-05-02 13:20:01,945 - INFO - Arguments validated successfully.
2025-05-02 13:20:01,946 - INFO - Clearing old checkpoints in models/checkpoints
2025-05-02 13:20:03,037 - INFO - Using CUDA for training.
2025-05-02 13:20:04,256 - INFO - TRAINING
2025-05-02 13:20:04,256 - INFO - ========
2025-05-02 13:20:04,257 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: Lex-EmoLex
Filter labels: ['Self-Transcendence']
Batch size: 4
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 4
Early stopping patience: 4
Multilayer: No
ResidualBlock: No
Previous sentences used: No
Using lexicon: EmoLex
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 10
Using data augmentation with paraphrasing: No
Adding topic detection features: No
Applying token pruning: No

2025-05-02 13:20:04,259 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'eval_loss': 0.2847854495048523, 'eval_f1-score': {'Humility': 0, 'Benevolence: caring': 0.1, 'Benevolence: dependability': 0.29, 'Universalism: concern': 0.69, 'Universalism: nature': 0.9, 'Universalism: tolerance': 0.38}, 'eval_macro-avg-f1-score': 0.39, 'eval_runtime': 17.1596, 'eval_samples_per_second': 103.615, 'eval_steps_per_second': 12.996, 'epoch': 1.0}
2025-05-02 13:23:37,264 - INFO - Skipping evaluation for warm-up phase (epoch 0).
{'eval_loss': 0.27297890186309814, 'eval_f1-score': {'Humility': 0.05, 'Benevolence: caring': 0.55, 'Benevolence: dependability': 0.35, 'Universalism: concern': 0.68, 'Universalism: nature': 0.89, 'Universalism: tolerance': 0.43}, 'eval_macro-avg-f1-score': 0.49, 'eval_runtime': 17.388, 'eval_samples_per_second': 102.255, 'eval_steps_per_second': 12.825, 'epoch': 2.0}
2025-05-02 13:27:25,306 - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'loss': 0.244, 'grad_norm': 3.147467851638794, 'learning_rate': 1.4117647058823532e-05, 'epoch': 2.94}
{'eval_loss': 0.28008347749710083, 'eval_f1-score': {'Humility': 0.3, 'Benevolence: caring': 0.55, 'Benevolence: dependability': 0.47, 'Universalism: concern': 0.67, 'Universalism: nature': 0.9, 'Universalism: tolerance': 0.48}, 'eval_macro-avg-f1-score': 0.56, 'eval_runtime': 17.105, 'eval_samples_per_second': 103.946, 'eval_steps_per_second': 13.037, 'epoch': 3.0}
{'eval_loss': 0.31479591131210327, 'eval_f1-score': {'Humility': 0.27, 'Benevolence: caring': 0.53, 'Benevolence: dependability': 0.5, 'Universalism: concern': 0.67, 'Universalism: nature': 0.9, 'Universalism: tolerance': 0.47}, 'eval_macro-avg-f1-score': 0.56, 'eval_runtime': 17.1001, 'eval_samples_per_second': 103.976, 'eval_steps_per_second': 13.041, 'epoch': 4.0}
{'eval_loss': 0.35031887888908386, 'eval_f1-score': {'Humility': 0.34, 'Benevolence: caring': 0.51, 'Benevolence: dependability': 0.49, 'Universalism: concern': 0.67, 'Universalism: nature': 0.91, 'Universalism: tolerance': 0.48}, 'eval_macro-avg-f1-score': 0.57, 'eval_runtime': 16.9031, 'eval_samples_per_second': 105.188, 'eval_steps_per_second': 13.193, 'epoch': 5.0}
{'loss': 0.0964, 'grad_norm': 4.330494403839111, 'learning_rate': 8.23529411764706e-06, 'epoch': 5.87}
{'eval_loss': 0.3670889139175415, 'eval_f1-score': {'Humility': 0.26, 'Benevolence: caring': 0.5, 'Benevolence: dependability': 0.52, 'Universalism: concern': 0.69, 'Universalism: nature': 0.91, 'Universalism: tolerance': 0.44}, 'eval_macro-avg-f1-score': 0.55, 'eval_runtime': 17.2185, 'eval_samples_per_second': 103.261, 'eval_steps_per_second': 12.951, 'epoch': 6.0}
{'eval_loss': 0.4025487005710602, 'eval_f1-score': {'Humility': 0.31, 'Benevolence: caring': 0.45, 'Benevolence: dependability': 0.54, 'Universalism: concern': 0.69, 'Universalism: nature': 0.9, 'Universalism: tolerance': 0.46}, 'eval_macro-avg-f1-score': 0.56, 'eval_runtime': 17.258, 'eval_samples_per_second': 103.025, 'eval_steps_per_second': 12.922, 'epoch': 7.0}
{'eval_loss': 0.4197269678115845, 'eval_f1-score': {'Humility': 0.33, 'Benevolence: caring': 0.49, 'Benevolence: dependability': 0.5, 'Universalism: concern': 0.69, 'Universalism: nature': 0.9, 'Universalism: tolerance': 0.44}, 'eval_macro-avg-f1-score': 0.56, 'eval_runtime': 17.3812, 'eval_samples_per_second': 102.295, 'eval_steps_per_second': 12.83, 'epoch': 8.0}
{'loss': 0.039, 'grad_norm': 1.7602355480194092, 'learning_rate': 2.3529411764705885e-06, 'epoch': 8.81}
{'eval_loss': 0.43471819162368774, 'eval_f1-score': {'Humility': 0.33, 'Benevolence: caring': 0.49, 'Benevolence: dependability': 0.54, 'Universalism: concern': 0.69, 'Universalism: nature': 0.9, 'Universalism: tolerance': 0.46}, 'eval_macro-avg-f1-score': 0.57, 'eval_runtime': 17.2667, 'eval_samples_per_second': 102.973, 'eval_steps_per_second': 12.915, 'epoch': 9.0}
{'train_runtime': 2058.4576, 'train_samples_per_second': 26.442, 'train_steps_per_second': 0.826, 'train_loss': 0.12441628280414302, 'epoch': 9.0}
2025-05-02 13:54:23,038 - INFO - 

VALIDATION
2025-05-02 13:54:23,038 - INFO - ==========
2025-05-02 13:54:39,378 - INFO - Humility: 0.34
2025-05-02 13:54:39,378 - INFO - Benevolence: caring: 0.51
2025-05-02 13:54:39,378 - INFO - Benevolence: dependability: 0.49
2025-05-02 13:54:39,378 - INFO - Universalism: concern: 0.67
2025-05-02 13:54:39,378 - INFO - Universalism: nature: 0.91
2025-05-02 13:54:39,378 - INFO - Universalism: tolerance: 0.48
2025-05-02 13:54:39,378 - INFO - Macro average: 0.57
2025-05-02 13:54:39,721 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-05-02 13:54:39,721 - INFO - Saving best model to models directory
2025-05-02 13:54:39,721 - INFO - UPLOAD to https://huggingface.co/Lex-EmoLex (using HF_TOKEN environment variable)
2025-05-02 13:54:39,721 - INFO - SAVE to models
