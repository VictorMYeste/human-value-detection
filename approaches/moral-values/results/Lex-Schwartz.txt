2025-06-02 11:22:32,493 - INFO - PyTorch version 2.2.2+cu118 available.
2025-06-02 11:22:32,493 - INFO - PyTorch version 2.2.2+cu118 available.
2025-06-02 11:22:44,202 - INFO - Setting random seed to 42
2025-06-02 11:22:44,202 - INFO - Running training for labels: ['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal', 'Security: societal', 'Tradition', 'Conformity: rules', 'Conformity: interpersonal', 'Humility', 'Benevolence: caring', 'Benevolence: dependability', 'Universalism: concern', 'Universalism: nature', 'Universalism: tolerance']
2025-06-02 11:22:44,202 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-06-02 11:22:44,426 - INFO - Loading lexicon embeddings for: Schwartz
2025-06-02 11:22:44,426 - INFO - Preparing datasets for training and validation
2025-06-02 11:23:42,236 - INFO - Arguments validated successfully.
2025-06-02 11:23:42,240 - INFO - Clearing old checkpoints in models/checkpoints
2025-06-02 11:23:43,316 - INFO - Using CUDA for training.
2025-06-02 11:23:44,456 - INFO - TRAINING
2025-06-02 11:23:44,456 - INFO - ========
2025-06-02 11:23:44,456 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: Lex-Schwartz
Filter labels: []
Batch size: 4
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 4
Early stopping patience: 4
Multilayer: No
ResidualBlock: No
Previous sentences used: No
Using lexicon: Schwartz
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 10
Using data augmentation with paraphrasing: No
Adding topic detection features: No
Applying token pruning: No

2025-06-02 11:23:44,457 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.1289, 'grad_norm': 0.406269907951355, 'learning_rate': 1.928469241773963e-05, 'epoch': 0.36}
{'loss': 0.103, 'grad_norm': 0.3744242787361145, 'learning_rate': 1.8569384835479257e-05, 'epoch': 0.71}
{'eval_loss': 0.09611666202545166, 'eval_f1-score': {'Self-direction: thought': 0, 'Self-direction: action': 0.06, 'Stimulation': 0.14, 'Hedonism': 0.2, 'Achievement': 0.28, 'Power: dominance': 0.16, 'Power: resources': 0.18, 'Face': 0.07, 'Security: personal': 0.15, 'Security: societal': 0.33, 'Tradition': 0.14, 'Conformity: rules': 0.03, 'Conformity: interpersonal': 0, 'Humility': 0, 'Benevolence: caring': 0.03, 'Benevolence: dependability': 0.11, 'Universalism: concern': 0.24, 'Universalism: nature': 0.45, 'Universalism: tolerance': 0.02}, 'eval_macro-avg-f1-score': 0.14, 'eval_runtime': 407.4715, 'eval_samples_per_second': 36.577, 'eval_steps_per_second': 4.572, 'epoch': 1.0}
2025-06-02 12:19:04,767 - INFO - Skipping evaluation for warm-up phase (epoch 0).
{'loss': 0.099, 'grad_norm': 0.43653038144111633, 'learning_rate': 1.7854077253218886e-05, 'epoch': 1.07}
{'loss': 0.0875, 'grad_norm': 0.5127538442611694, 'learning_rate': 1.7138769670958512e-05, 'epoch': 1.43}
{'loss': 0.088, 'grad_norm': 0.42466863989830017, 'learning_rate': 1.642346208869814e-05, 'epoch': 1.79}
{'eval_loss': 0.09384425729513168, 'eval_f1-score': {'Self-direction: thought': 0, 'Self-direction: action': 0.14, 'Stimulation': 0.15, 'Hedonism': 0.25, 'Achievement': 0.27, 'Power: dominance': 0.29, 'Power: resources': 0.15, 'Face': 0.2, 'Security: personal': 0.2, 'Security: societal': 0.4, 'Tradition': 0.34, 'Conformity: rules': 0.42, 'Conformity: interpersonal': 0, 'Humility': 0, 'Benevolence: caring': 0.03, 'Benevolence: dependability': 0.09, 'Universalism: concern': 0.31, 'Universalism: nature': 0.56, 'Universalism: tolerance': 0.09}, 'eval_macro-avg-f1-score': 0.2, 'eval_runtime': 409.7581, 'eval_samples_per_second': 36.373, 'eval_steps_per_second': 4.547, 'epoch': 2.0}
2025-06-02 13:16:44,265 - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'loss': 0.0825, 'grad_norm': 0.5630273222923279, 'learning_rate': 1.570815450643777e-05, 'epoch': 2.14}
{'loss': 0.0721, 'grad_norm': 0.48571112751960754, 'learning_rate': 1.4992846924177399e-05, 'epoch': 2.5}
{'loss': 0.0739, 'grad_norm': 0.5536102652549744, 'learning_rate': 1.4277539341917026e-05, 'epoch': 2.86}
{'eval_loss': 0.10039179027080536, 'eval_f1-score': {'Self-direction: thought': 0.06, 'Self-direction: action': 0.24, 'Stimulation': 0.35, 'Hedonism': 0.28, 'Achievement': 0.32, 'Power: dominance': 0.29, 'Power: resources': 0.24, 'Face': 0.27, 'Security: personal': 0.3, 'Security: societal': 0.4, 'Tradition': 0.4, 'Conformity: rules': 0.44, 'Conformity: interpersonal': 0.01, 'Humility': 0, 'Benevolence: caring': 0.21, 'Benevolence: dependability': 0.24, 'Universalism: concern': 0.29, 'Universalism: nature': 0.56, 'Universalism: tolerance': 0.22}, 'eval_macro-avg-f1-score': 0.27, 'eval_runtime': 406.6934, 'eval_samples_per_second': 36.647, 'eval_steps_per_second': 4.581, 'epoch': 3.0}
{'loss': 0.0644, 'grad_norm': 0.6412036418914795, 'learning_rate': 1.3562231759656654e-05, 'epoch': 3.22}
{'loss': 0.0582, 'grad_norm': 0.6687749028205872, 'learning_rate': 1.284692417739628e-05, 'epoch': 3.57}
{'loss': 0.0595, 'grad_norm': 0.5477409958839417, 'learning_rate': 1.213161659513591e-05, 'epoch': 3.93}
{'eval_loss': 0.10680210590362549, 'eval_f1-score': {'Self-direction: thought': 0.08, 'Self-direction: action': 0.19, 'Stimulation': 0.28, 'Hedonism': 0.26, 'Achievement': 0.3, 'Power: dominance': 0.34, 'Power: resources': 0.28, 'Face': 0.24, 'Security: personal': 0.31, 'Security: societal': 0.43, 'Tradition': 0.43, 'Conformity: rules': 0.45, 'Conformity: interpersonal': 0.15, 'Humility': 0, 'Benevolence: caring': 0.18, 'Benevolence: dependability': 0.18, 'Universalism: concern': 0.31, 'Universalism: nature': 0.54, 'Universalism: tolerance': 0.24}, 'eval_macro-avg-f1-score': 0.27, 'eval_runtime': 412.3566, 'eval_samples_per_second': 36.143, 'eval_steps_per_second': 4.518, 'epoch': 4.0}
{'loss': 0.0483, 'grad_norm': 0.8016683459281921, 'learning_rate': 1.1416309012875537e-05, 'epoch': 4.29}
{'loss': 0.0455, 'grad_norm': 0.8810215592384338, 'learning_rate': 1.0701001430615166e-05, 'epoch': 4.65}
{'eval_loss': 0.11602292954921722, 'eval_f1-score': {'Self-direction: thought': 0.06, 'Self-direction: action': 0.2, 'Stimulation': 0.26, 'Hedonism': 0.24, 'Achievement': 0.32, 'Power: dominance': 0.32, 'Power: resources': 0.28, 'Face': 0.25, 'Security: personal': 0.3, 'Security: societal': 0.41, 'Tradition': 0.4, 'Conformity: rules': 0.44, 'Conformity: interpersonal': 0.1, 'Humility': 0, 'Benevolence: caring': 0.22, 'Benevolence: dependability': 0.24, 'Universalism: concern': 0.32, 'Universalism: nature': 0.51, 'Universalism: tolerance': 0.24}, 'eval_macro-avg-f1-score': 0.27, 'eval_runtime': 408.3629, 'eval_samples_per_second': 36.497, 'eval_steps_per_second': 4.562, 'epoch': 5.0}
{'loss': 0.0452, 'grad_norm': 0.5011468529701233, 'learning_rate': 9.985693848354794e-06, 'epoch': 5.0}
{'loss': 0.0345, 'grad_norm': 0.8658470511436462, 'learning_rate': 9.270386266094421e-06, 'epoch': 5.36}
{'loss': 0.0344, 'grad_norm': 1.123926043510437, 'learning_rate': 8.555078683834049e-06, 'epoch': 5.72}
{'eval_loss': 0.12571761012077332, 'eval_f1-score': {'Self-direction: thought': 0.07, 'Self-direction: action': 0.22, 'Stimulation': 0.25, 'Hedonism': 0.24, 'Achievement': 0.33, 'Power: dominance': 0.31, 'Power: resources': 0.28, 'Face': 0.27, 'Security: personal': 0.24, 'Security: societal': 0.4, 'Tradition': 0.39, 'Conformity: rules': 0.44, 'Conformity: interpersonal': 0.1, 'Humility': 0, 'Benevolence: caring': 0.22, 'Benevolence: dependability': 0.22, 'Universalism: concern': 0.31, 'Universalism: nature': 0.51, 'Universalism: tolerance': 0.25}, 'eval_macro-avg-f1-score': 0.27, 'eval_runtime': 406.814, 'eval_samples_per_second': 36.636, 'eval_steps_per_second': 4.579, 'epoch': 6.0}
{'loss': 0.0329, 'grad_norm': 0.5766515731811523, 'learning_rate': 7.839771101573678e-06, 'epoch': 6.08}
{'loss': 0.0262, 'grad_norm': 1.058066964149475, 'learning_rate': 7.124463519313305e-06, 'epoch': 6.43}
{'loss': 0.027, 'grad_norm': 0.9998041391372681, 'learning_rate': 6.409155937052933e-06, 'epoch': 6.79}
{'eval_loss': 0.1356174349784851, 'eval_f1-score': {'Self-direction: thought': 0.07, 'Self-direction: action': 0.23, 'Stimulation': 0.26, 'Hedonism': 0.26, 'Achievement': 0.33, 'Power: dominance': 0.31, 'Power: resources': 0.28, 'Face': 0.27, 'Security: personal': 0.24, 'Security: societal': 0.4, 'Tradition': 0.36, 'Conformity: rules': 0.44, 'Conformity: interpersonal': 0.12, 'Humility': 0, 'Benevolence: caring': 0.2, 'Benevolence: dependability': 0.25, 'Universalism: concern': 0.33, 'Universalism: nature': 0.49, 'Universalism: tolerance': 0.21}, 'eval_macro-avg-f1-score': 0.27, 'eval_runtime': 412.5887, 'eval_samples_per_second': 36.123, 'eval_steps_per_second': 4.515, 'epoch': 7.0}
{'train_runtime': 23821.7588, 'train_samples_per_second': 18.789, 'train_steps_per_second': 0.587, 'train_loss': 0.06262271127397882, 'epoch': 7.0}
2025-06-02 18:00:46,609 - INFO - 

VALIDATION
2025-06-02 18:00:46,609 - INFO - ==========
2025-06-02 18:07:38,013 - INFO - Self-direction: thought: 0.06
2025-06-02 18:07:38,013 - INFO - Self-direction: action: 0.24
2025-06-02 18:07:38,013 - INFO - Stimulation: 0.35
2025-06-02 18:07:38,013 - INFO - Hedonism: 0.28
2025-06-02 18:07:38,013 - INFO - Achievement: 0.32
2025-06-02 18:07:38,013 - INFO - Power: dominance: 0.29
2025-06-02 18:07:38,013 - INFO - Power: resources: 0.24
2025-06-02 18:07:38,013 - INFO - Face: 0.27
2025-06-02 18:07:38,013 - INFO - Security: personal: 0.30
2025-06-02 18:07:38,013 - INFO - Security: societal: 0.40
2025-06-02 18:07:38,013 - INFO - Tradition: 0.40
2025-06-02 18:07:38,013 - INFO - Conformity: rules: 0.44
2025-06-02 18:07:38,013 - INFO - Conformity: interpersonal: 0.01
2025-06-02 18:07:38,013 - INFO - Humility: 0.00
2025-06-02 18:07:38,013 - INFO - Benevolence: caring: 0.21
2025-06-02 18:07:38,013 - INFO - Benevolence: dependability: 0.24
2025-06-02 18:07:38,013 - INFO - Universalism: concern: 0.29
2025-06-02 18:07:38,013 - INFO - Universalism: nature: 0.56
2025-06-02 18:07:38,013 - INFO - Universalism: tolerance: 0.22
2025-06-02 18:07:38,013 - INFO - Macro average: 0.27
2025-06-02 18:07:38,014 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
2025-06-02 18:07:38,014 - INFO - Saving best model to models directory
2025-06-02 18:07:38,014 - INFO - UPLOAD to https://huggingface.co/Lex-Schwartz (using HF_TOKEN environment variable)
2025-06-02 18:07:38,014 - INFO - SAVE to models
