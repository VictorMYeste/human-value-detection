==========
==========
==========
===== Baseline =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Baseline (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:01:37,216 - INFO - Using device: cuda
2025-05-28 15:01:37,424 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.41  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.52  Recall: 0.43  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.40  Recall: 0.43  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.08  Recall: 0.05  F1: 0.06

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.50  Recall: 0.07  F1: 0.12

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.21  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.21  F1: 0.25

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.40  Recall: 0.40  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.57  Recall: 0.58  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.15  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:02:17,628 - INFO - Using device: cuda
2025-05-28 15:02:17,783 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.59  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.55  F1: 0.44

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.40

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.09  Recall: 0.15  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.10  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.31  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.31  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.46  F1: 0.37

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.72  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.23  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Baseline (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:03:06,029 - INFO - Using device: cuda
2025-05-28 15:03:06,152 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.88  F1: 0.92
  Class 1 (positive)
    Precision: 0.30  Recall: 0.59  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.52  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.91  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.59  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.09  Recall: 0.14  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.17  Recall: 0.07  F1: 0.10

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.33  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.32  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.47  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.70  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.22  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Baseline (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:03:54,473 - INFO - Using device: cuda
2025-05-28 15:03:54,597 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.59  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.53  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.91  F1: 0.94
  Class 1 (positive)
    Precision: 0.31  Recall: 0.58  F1: 0.40

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.08  Recall: 0.12  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.12  Recall: 0.07  F1: 0.09

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.20  Recall: 0.33  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.32  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.47  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.47  Recall: 0.70  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.22  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Baseline (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:04:42,737 - INFO - Using device: cuda
2025-05-28 15:04:42,859 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.60  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.36  Recall: 0.52  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.58  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.08  Recall: 0.11  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.12  Recall: 0.07  F1: 0.09

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.32  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.32  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.47  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.70  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.21  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
-----------------------------------------------------
==========
==========
==========
===== NER =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== NER (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:05:30,917 - INFO - Using device: cuda
2025-05-28 15:05:31,040 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.39  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.59  Recall: 0.41  F1: 0.48

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.41  Recall: 0.42  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.04  F1: 0.06

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.20  Recall: 0.03  F1: 0.06

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.20  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.21  F1: 0.25

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.41  Recall: 0.42  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.58  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.14  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:08:23,832 - INFO - Using device: cuda
2025-05-28 15:08:23,956 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.57  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.51  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.32  Recall: 0.56  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.11  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.05  Recall: 0.03  F1: 0.04

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.30  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.31  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.49  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.73  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.20  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== NER (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:13:23,257 - INFO - Using device: cuda
2025-05-28 15:13:23,379 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.57  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.49  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.59  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.11  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.06  Recall: 0.03  F1: 0.04

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.20  Recall: 0.32  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.50  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.71  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.20  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== NER (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:18:22,329 - INFO - Using device: cuda
2025-05-28 15:18:22,452 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.57  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.50  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.59  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.05  Recall: 0.03  F1: 0.04

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.32  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.32  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.50  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.71  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.21  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== NER (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:23:20,360 - INFO - Using device: cuda
2025-05-28 15:23:20,484 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.57  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.49  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.33  Recall: 0.58  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.09  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.05  Recall: 0.03  F1: 0.04

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.20  Recall: 0.31  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.50  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.71  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.20  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
-----------------------------------------------------
==========
==========
==========
===== Lex-Schwartz =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-Schwartz (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:28:16,204 - INFO - Using device: cuda
2025-05-28 15:28:16,327 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.96  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.37  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.60  Recall: 0.40  F1: 0.48

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.97  F1: 0.96
  Class 1 (positive)
    Precision: 0.44  Recall: 0.39  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.02  F1: 0.03

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.19  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.35  Recall: 0.23  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.41  Recall: 0.44  F1: 0.43

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.54  Recall: 0.61  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.25  Recall: 0.11  F1: 0.15

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:28:53,889 - INFO - Using device: cuda
2025-05-28 15:28:54,012 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.50  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.51  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.10  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.29  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.51  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.77  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.15  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-Schwartz (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:29:47,544 - INFO - Using device: cuda
2025-05-28 15:29:47,668 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.48  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.55  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.10  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.31  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.33  F1: 0.31

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.75  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.15  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-Schwartz (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:30:41,152 - INFO - Using device: cuda
2025-05-28 15:30:41,276 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.33  Recall: 0.54  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.49  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.55  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.08  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.31  F1: 0.27

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.33  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.51  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.75  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.16  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-Schwartz (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:31:34,702 - INFO - Using device: cuda
2025-05-28 15:31:34,825 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.47  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.54  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.08  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.30  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.28  Recall: 0.32  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.75  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.20  Recall: 0.15  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
-----------------------------------------------------
==========
==========
==========
===== Lex-VAD =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-VAD (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:32:27,845 - INFO - Using device: cuda
2025-05-28 15:32:27,968 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.38  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.56  Recall: 0.45  F1: 0.50

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.42  Recall: 0.41  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.03  F1: 0.05

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.32  Recall: 0.20  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.35  Recall: 0.20  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.43  Recall: 0.44  F1: 0.43

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.60  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.10  F1: 0.14

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:33:03,648 - INFO - Using device: cuda
2025-05-28 15:33:03,772 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.57  F1: 0.48

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.54  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.29  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.30  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.50  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.75  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.16  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-VAD (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:33:53,188 - INFO - Using device: cuda
2025-05-28 15:33:53,311 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.55  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.33  Recall: 0.57  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.30  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.31  F1: 0.31

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.50  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.72  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.15  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-VAD (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:34:43,001 - INFO - Using device: cuda
2025-05-28 15:34:43,124 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.57  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.55  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.33  Recall: 0.57  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.07  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.31  F1: 0.27

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.31  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.50  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.72  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.15  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-VAD (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:35:32,673 - INFO - Using device: cuda
2025-05-28 15:35:32,796 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.57  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.54  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.57  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.08  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.30  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.31  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.34  Recall: 0.50  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.73  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.14  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
-----------------------------------------------------
==========
==========
==========
===== Lex-EmoLex =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-EmoLex (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:36:21,950 - INFO - Using device: cuda
2025-05-28 15:36:22,073 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.37  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.60  Recall: 0.40  F1: 0.48

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.97  F1: 0.96
  Class 1 (positive)
    Precision: 0.44  Recall: 0.39  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.02  F1: 0.03

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.19  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.33  Recall: 0.22  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.40  Recall: 0.45  F1: 0.43

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.54  Recall: 0.62  F1: 0.58

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.11  F1: 0.15

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:36:57,678 - INFO - Using device: cuda
2025-05-28 15:36:57,801 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.50  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.51  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.28  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.30  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.78  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.16  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-EmoLex (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:37:47,569 - INFO - Using device: cuda
2025-05-28 15:37:47,693 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.48  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.54  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.29  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.28  Recall: 0.32  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.75  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.16  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-EmoLex (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:38:37,416 - INFO - Using device: cuda
2025-05-28 15:38:37,540 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.33  Recall: 0.54  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.49  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.54  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.07  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.30  F1: 0.27

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.32  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.75  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.17  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-EmoLex (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:39:26,808 - INFO - Using device: cuda
2025-05-28 15:39:26,931 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.47  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.54  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.08  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.28  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.76  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.20  Recall: 0.15  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
-----------------------------------------------------
==========
==========
==========
===== Lex-MFD =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-MFD (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:40:16,224 - INFO - Using device: cuda
2025-05-28 15:40:16,348 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.96  F1: 0.95
  Class 1 (positive)
    Precision: 0.42  Recall: 0.37  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.59  Recall: 0.41  F1: 0.49

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.97  F1: 0.96
  Class 1 (positive)
    Precision: 0.44  Recall: 0.39  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.02  F1: 0.03

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.19  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.34  Recall: 0.21  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.41  Recall: 0.45  F1: 0.43

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.53  Recall: 0.61  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.26  Recall: 0.12  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:40:51,527 - INFO - Using device: cuda
2025-05-28 15:40:51,650 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.33  Recall: 0.53  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.51  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.51  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.10  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.29  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.30  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.77  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.17  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-MFD (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:41:40,989 - INFO - Using device: cuda
2025-05-28 15:41:41,114 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.49  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.55  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.10  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.30  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.31  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.74  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.17  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-MFD (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:42:30,677 - INFO - Using device: cuda
2025-05-28 15:42:30,800 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.91  F1: 0.93
  Class 1 (positive)
    Precision: 0.33  Recall: 0.54  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.50  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.55  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.08  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.31  F1: 0.27

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.31  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.33  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.74  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.18  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-MFD (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:43:19,904 - INFO - Using device: cuda
2025-05-28 15:43:20,027 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.33  Recall: 0.54  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.48  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.54  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.08  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.30  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.30  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.52  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.75  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.16  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
-----------------------------------------------------
==========
==========
==========
===== Lex-LIWC-22 =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-LIWC-22 (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:44:09,056 - INFO - Using device: cuda
2025-05-28 15:44:09,179 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.38  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.54  Recall: 0.41  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.97  F1: 0.96
  Class 1 (positive)
    Precision: 0.45  Recall: 0.40  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.07  Recall: 0.02  F1: 0.03

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.17  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.34  Recall: 0.23  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.39  Recall: 0.46  F1: 0.42

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.56  Recall: 0.60  F1: 0.58

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.09  F1: 0.13

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.29
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:44:48,073 - INFO - Using device: cuda
2025-05-28 15:44:48,196 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.40  Recall: 0.51  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.52  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.11  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.26  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.32  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.74  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.14  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-LIWC-22 (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:45:41,521 - INFO - Using device: cuda
2025-05-28 15:45:41,645 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.30  Recall: 0.56  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.40  Recall: 0.49  F1: 0.44

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.56  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.11  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.27  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.33  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.72  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.13  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-LIWC-22 (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:46:34,497 - INFO - Using device: cuda
2025-05-28 15:46:34,620 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.50  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.55  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.10  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.28  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.34  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.46  Recall: 0.72  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.14  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-LIWC-22 (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:47:27,280 - INFO - Using device: cuda
2025-05-28 15:47:27,404 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.39  Recall: 0.48  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.37  Recall: 0.55  F1: 0.44

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.26  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.33  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.53  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.72  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.21  Recall: 0.13  F1: 0.17

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
-----------------------------------------------------
==========
==========
==========
===== Lex-LIWC-22_LingFeat =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-LIWC-22_LingFeat (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:48:19,885 - INFO - Using device: cuda
2025-05-28 15:48:20,008 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.37  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.49  Recall: 0.45  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.42  Recall: 0.43  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.13  Recall: 0.07  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.29  Recall: 0.07  F1: 0.11

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.21  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.24  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.38  Recall: 0.44  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.56  Recall: 0.58  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.20  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.32
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:49:21,296 - INFO - Using device: cuda
2025-05-28 15:49:21,419 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.34  Recall: 0.59  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.33  Recall: 0.57  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.11  Recall: 0.17  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.09  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.17  Recall: 0.29  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.34  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.29  Recall: 0.52  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.72  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.28  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-LIWC-22_LingFeat (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:50:52,836 - INFO - Using device: cuda
2025-05-28 15:50:52,960 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.35  Recall: 0.57  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.60  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.18  F1: 0.15

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.11  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.17  Recall: 0.31  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.35  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.30  Recall: 0.52  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.70  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.28  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-LIWC-22_LingFeat (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:52:24,442 - INFO - Using device: cuda
2025-05-28 15:52:24,565 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.33  Recall: 0.55  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.36  Recall: 0.57  F1: 0.44

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.60  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.16  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.09  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.31  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.36  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.30  Recall: 0.52  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.70  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.29  F1: 0.23

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.32
==========
===== Lex-LIWC-22_LingFeat (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:53:54,532 - INFO - Using device: cuda
2025-05-28 15:53:54,655 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.34  Recall: 0.56  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.33  Recall: 0.60  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.16  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.09  Recall: 0.07  F1: 0.08

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.30  F1: 0.23

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.35  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.30  Recall: 0.52  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.71  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.19  Recall: 0.27  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
-----------------------------------------------------
==========
==========
==========
===== Lex-MFD-20 =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-MFD-20 (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:55:25,088 - INFO - Using device: cuda
2025-05-28 15:55:25,211 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.38  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.47  Recall: 0.43  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.41  Recall: 0.42  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.07  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.17  F1: 0.20

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.28  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.40  Recall: 0.41  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.57  F1: 0.56

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.20  Recall: 0.18  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 15:56:03,819 - INFO - Using device: cuda
2025-05-28 15:56:03,942 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.33  Recall: 0.55  F1: 0.41

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.95
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.09  Recall: 0.20  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.17  Recall: 0.25  F1: 0.20

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.38  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.48  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.71  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.17  Recall: 0.25  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.29
==========
===== Lex-MFD-20 (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 15:56:55,952 - INFO - Using device: cuda
2025-05-28 15:56:56,076 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.33  Recall: 0.52  F1: 0.40

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.58  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.11  Recall: 0.23  F1: 0.15

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.17  Recall: 0.26  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.39  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.49  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.69  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.16  Recall: 0.24  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-MFD-20 (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 15:57:48,072 - INFO - Using device: cuda
2025-05-28 15:57:48,195 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.33  Recall: 0.53  F1: 0.41

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.58  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.10  Recall: 0.20  F1: 0.14

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.26  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.40  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.49  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.46  Recall: 0.69  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.17  Recall: 0.25  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-MFD-20 (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 15:58:40,048 - INFO - Using device: cuda
2025-05-28 15:58:40,172 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.32  Recall: 0.51  F1: 0.39

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.33  Recall: 0.57  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.10  Recall: 0.19  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.25  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.38  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.32  Recall: 0.49  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.70  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.17  Recall: 0.24  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.29
-----------------------------------------------------
==========
==========
==========
===== Lex-eMFD =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-eMFD (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 15:59:31,956 - INFO - Using device: cuda
2025-05-28 15:59:32,080 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.37  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.50  Recall: 0.42  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.41  Recall: 0.43  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.07  F1: 0.07

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.17  F1: 0.20

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.29  Recall: 0.27  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.39  Recall: 0.42  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.55  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.18  Recall: 0.18  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 16:00:10,258 - INFO - Using device: cuda
2025-05-28 16:00:10,381 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.53  F1: 0.44

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.56  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.09  Recall: 0.22  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.23  F1: 0.20

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.36  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.30  Recall: 0.50  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.70  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.16  Recall: 0.26  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-eMFD (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 16:01:02,509 - INFO - Using device: cuda
2025-05-28 16:01:02,632 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.54  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.51  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.91  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.59  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.10  Recall: 0.24  F1: 0.14

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.18  Recall: 0.25  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.38  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.50  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.67  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.16  Recall: 0.25  F1: 0.19

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-eMFD (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 16:01:54,621 - INFO - Using device: cuda
2025-05-28 16:01:54,744 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.54  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.37  Recall: 0.52  F1: 0.43

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.91  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.59  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.09  Recall: 0.21  F1: 0.13

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.26  F1: 0.22

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.22  Recall: 0.38  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.50  F1: 0.38

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.67  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.16  Recall: 0.26  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
===== Lex-eMFD (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 16:02:46,536 - INFO - Using device: cuda
2025-05-28 16:02:46,660 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.36  Recall: 0.50  F1: 0.42

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.92  F1: 0.94
  Class 1 (positive)
    Precision: 0.32  Recall: 0.58  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.09  Recall: 0.20  F1: 0.12

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.24  F1: 0.21

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.37  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.96
  Class 1 (positive)
    Precision: 0.31  Recall: 0.50  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.68  F1: 0.53

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.16  Recall: 0.25  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
-----------------------------------------------------
==========
==========
==========
===== Lex-MJD =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== Lex-MJD (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 16:03:38,304 - INFO - Using device: cuda
2025-05-28 16:03:38,427 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.41  Recall: 0.38  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.55  Recall: 0.45  F1: 0.50

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.97  F1: 0.96
  Class 1 (positive)
    Precision: 0.43  Recall: 0.39  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.03  F1: 0.05

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.23  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.33  Recall: 0.22  F1: 0.26

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.43  Recall: 0.43  F1: 0.43

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.54  Recall: 0.60  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.26  Recall: 0.13  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.30
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 16:04:16,764 - INFO - Using device: cuda
2025-05-28 16:04:16,888 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.56  F1: 0.48

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.52  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.11  Recall: 0.11  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.34  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.31  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.48  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.43  Recall: 0.75  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.20  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-MJD (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 16:05:08,836 - INFO - Using device: cuda
2025-05-28 16:05:08,960 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.89  F1: 0.92
  Class 1 (positive)
    Precision: 0.31  Recall: 0.56  F1: 0.39

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.54  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.55  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.13  Recall: 0.11  F1: 0.12

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.19  Recall: 0.35  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.33  F1: 0.30

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.36  Recall: 0.49  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.73  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.19  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-MJD (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 16:06:01,632 - INFO - Using device: cuda
2025-05-28 16:06:01,756 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.54  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.55  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.09  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.21  Recall: 0.37  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.33  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.36  Recall: 0.49  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.74  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.20  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== Lex-MJD (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 16:06:53,460 - INFO - Using device: cuda
2025-05-28 16:06:53,583 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.56  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.53  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.36  Recall: 0.55  F1: 0.43

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.12  Recall: 0.10  F1: 0.11

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.00  Recall: 0.00  F1: 0.00

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.97  F1: 0.98
  Class 1 (positive)
    Precision: 0.20  Recall: 0.35  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.27  Recall: 0.32  F1: 0.29

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.49  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.42  Recall: 0.74  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.22  Recall: 0.19  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
-----------------------------------------------------
==========
==========
==========
===== TD-LDA =====
==========
==========
==========
==========
==========
===== Fixed Threshold (0.5) =====
==========
==========
==========
===== TD-LDA (based on Social Focus = TD-NMF) =====
==========
----- Predicting Test -----
2025-05-28 16:07:45,896 - INFO - Using device: cuda
2025-05-28 16:07:46,019 - INFO - Hierarchical run ➜ 3921 / 14569 sentences will be processed by the value model (threshold=0.5)
2025-05-28 16:08:10,710 - INFO - Using topic_feature_dim = 60
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.95  Recall: 0.95  F1: 0.95
  Class 1 (positive)
    Precision: 0.40  Recall: 0.37  F1: 0.38

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.57  Recall: 0.44  F1: 0.50

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.97  F1: 0.96
  Class 1 (positive)
    Precision: 0.43  Recall: 0.39  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.03  F1: 0.05

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.67  Recall: 0.07  F1: 0.12

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.26  Recall: 0.26  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.98  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.30  Recall: 0.22  F1: 0.25

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.97  F1: 0.97
  Class 1 (positive)
    Precision: 0.42  Recall: 0.39  F1: 0.41

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.56  Recall: 0.58  F1: 0.57

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 1.00  F1: 0.99
  Class 1 (positive)
    Precision: 0.28  Recall: 0.13  F1: 0.18

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
==========
===== Tuned Threshold =====
==========
==========
==========
===== Baseline (based on Social Focus = Previous-Sentences-2) =====
==========
----- Predicting Test -----
2025-05-28 16:08:45,461 - INFO - Using device: cuda
2025-05-28 16:08:45,584 - INFO - Hierarchical run ➜ 7210 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-28 16:09:09,516 - INFO - Using topic_feature_dim = 60
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.55  F1: 0.47

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.94  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.51  F1: 0.41

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.09  F1: 0.09

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.22  Recall: 0.07  F1: 0.10

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.18  Recall: 0.37  F1: 0.24

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.23  Recall: 0.32  F1: 0.27

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.95  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.45  F1: 0.39

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.45  Recall: 0.72  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.25  Recall: 0.19  F1: 0.22

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== TD-LDA (based on Social Focus = NER) =====
==========
----- Predicting Test -----
2025-05-28 16:09:58,208 - INFO - Using device: cuda
2025-05-28 16:09:58,332 - INFO - Hierarchical run ➜ 7271 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-28 16:10:22,457 - INFO - Using topic_feature_dim = 60
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.31  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.39  Recall: 0.52  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.54  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.10  Recall: 0.10  F1: 0.10

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.33  Recall: 0.07  F1: 0.11

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.18  Recall: 0.38  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.33  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.45  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.70  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.24  Recall: 0.18  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
==========
===== TD-LDA (based on Social Focus = Lex - WorryWords) =====
==========
----- Predicting Test -----
2025-05-28 16:11:10,932 - INFO - Using device: cuda
2025-05-28 16:11:11,055 - INFO - Hierarchical run ➜ 7169 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-28 16:11:35,451 - INFO - Using topic_feature_dim = 60
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.41

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.41  Recall: 0.53  F1: 0.46

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.34  Recall: 0.54  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.08  F1: 0.08

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.29  Recall: 0.07  F1: 0.11

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.19  Recall: 0.39  F1: 0.26

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.24  Recall: 0.33  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.45  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.46  Recall: 0.70  F1: 0.55

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.25  Recall: 0.19  F1: 0.21

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.32
==========
===== TD-LDA (based on Social Focus = Lex - LIWC 15) =====
==========
----- Predicting Test -----
2025-05-28 16:12:23,853 - INFO - Using device: cuda
2025-05-28 16:12:23,976 - INFO - Hierarchical run ➜ 7139 / 14569 sentences will be processed by the value model (threshold=0.1)
2025-05-28 16:12:48,092 - INFO - Using topic_feature_dim = 60
----- Evaluating Test -----

Label: Security: societal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.96  Recall: 0.90  F1: 0.93
  Class 1 (positive)
    Precision: 0.32  Recall: 0.55  F1: 0.40

Label: Tradition  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.40  Recall: 0.52  F1: 0.45

Label: Conformity: rules  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.93  F1: 0.95
  Class 1 (positive)
    Precision: 0.35  Recall: 0.53  F1: 0.42

Label: Conformity: interpersonal  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.09  Recall: 0.08  F1: 0.08

Label: Humility  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 1.00  Recall: 1.00  F1: 1.00
  Class 1 (positive)
    Precision: 0.22  Recall: 0.07  F1: 0.10

Label: Benevolence: caring  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.96  F1: 0.97
  Class 1 (positive)
    Precision: 0.19  Recall: 0.38  F1: 0.25

Label: Benevolence: dependability  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.98
  Class 1 (positive)
    Precision: 0.25  Recall: 0.32  F1: 0.28

Label: Universalism: concern  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.97  Recall: 0.96  F1: 0.96
  Class 1 (positive)
    Precision: 0.35  Recall: 0.45  F1: 0.40

Label: Universalism: nature  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.98  F1: 0.99
  Class 1 (positive)
    Precision: 0.44  Recall: 0.70  F1: 0.54

Label: Universalism: tolerance  |  Fixed 0.50 threshold
  Class 0 (negative)
    Precision: 0.99  Recall: 0.99  F1: 0.99
  Class 1 (positive)
    Precision: 0.23  Recall: 0.18  F1: 0.20

=== SUMMARY =================================================

Macro-average F1 (fixed 0.50 threshold) across 10 labels: 0.31
