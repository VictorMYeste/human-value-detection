2024-12-16 15:01:43,994 - HVD - INFO - Initializing tokenizer for model: microsoft/deberta-base
2024-12-16 15:01:44,246 - HVD - INFO - Loading lexicon embeddings for: No lexicon used
2024-12-16 15:01:44,247 - HVD - INFO - Preparing datasets for training and validation
2024-12-16 15:02:02,589 - HVD - INFO - Arguments validated successfully.
2024-12-16 15:02:03,022 - HVD - INFO - Using CUDA for training.
2024-12-16 15:02:04,283 - HVD - INFO - TRAINING
2024-12-16 15:02:04,284 - HVD - INFO - ========
2024-12-16 15:02:04,284 - HVD - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: Text-v8
Batch size: 4
Number of epochs: 10
Learning rate: 1e-05
Weight decay: 0.001
Gradient accumulation steps: 16
Early stopping patience: 7
Previous sentences used: No
Using lexicon: No
Adding linguistic features: No
Number of categories (lexicon): 0

2024-12-16 15:02:04,289 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'eval_loss': 0.6474659442901611, 'eval_f1-score': {'Presence': 0.67}, 'eval_marco-avg-f1-score': 0.67, 'eval_runtime': 326.975, 'eval_samples_per_second': 45.581, 'eval_steps_per_second': 5.698, 'epoch': 1.0}
{'loss': 0.6465, 'grad_norm': 96988.890625, 'learning_rate': 8.567335243553008e-06, 'epoch': 1.43}
{'eval_loss': 0.6479036211967468, 'eval_f1-score': {'Presence': 0.62}, 'eval_marco-avg-f1-score': 0.62, 'eval_runtime': 327.4024, 'eval_samples_per_second': 45.522, 'eval_steps_per_second': 5.69, 'epoch': 2.0}
{'loss': 0.6033, 'grad_norm': 185885.453125, 'learning_rate': 7.134670487106018e-06, 'epoch': 2.86}
{'eval_loss': 0.6573008894920349, 'eval_f1-score': {'Presence': 0.61}, 'eval_marco-avg-f1-score': 0.61, 'eval_runtime': 327.1453, 'eval_samples_per_second': 45.558, 'eval_steps_per_second': 5.695, 'epoch': 3.0}
{'eval_loss': 0.6807644963264465, 'eval_f1-score': {'Presence': 0.58}, 'eval_marco-avg-f1-score': 0.58, 'eval_runtime': 326.8536, 'eval_samples_per_second': 45.598, 'eval_steps_per_second': 5.7, 'epoch': 4.0}
{'loss': 0.5513, 'grad_norm': 276927.3125, 'learning_rate': 5.7020057306590255e-06, 'epoch': 4.29}
{'eval_loss': 0.7045269012451172, 'eval_f1-score': {'Presence': 0.62}, 'eval_marco-avg-f1-score': 0.62, 'eval_runtime': 327.3101, 'eval_samples_per_second': 45.535, 'eval_steps_per_second': 5.692, 'epoch': 5.0}
{'loss': 0.4982, 'grad_norm': 505559.5, 'learning_rate': 4.269340974212035e-06, 'epoch': 5.72}
{'eval_loss': 0.7378445267677307, 'eval_f1-score': {'Presence': 0.61}, 'eval_marco-avg-f1-score': 0.61, 'eval_runtime': 327.0301, 'eval_samples_per_second': 45.574, 'eval_steps_per_second': 5.697, 'epoch': 6.0}
{'eval_loss': 0.7753982543945312, 'eval_f1-score': {'Presence': 0.62}, 'eval_marco-avg-f1-score': 0.62, 'eval_runtime': 326.7707, 'eval_samples_per_second': 45.61, 'eval_steps_per_second': 5.701, 'epoch': 7.0}
{'loss': 0.4501, 'grad_norm': 371111.09375, 'learning_rate': 2.836676217765043e-06, 'epoch': 7.15}
{'eval_loss': 0.8134637475013733, 'eval_f1-score': {'Presence': 0.61}, 'eval_marco-avg-f1-score': 0.61, 'eval_runtime': 326.5306, 'eval_samples_per_second': 45.643, 'eval_steps_per_second': 5.705, 'epoch': 8.0}
{'train_runtime': 21208.97, 'train_samples_per_second': 21.103, 'train_steps_per_second': 0.165, 'train_loss': 0.5359924829215035, 'epoch': 8.0}
2024-12-16 20:55:33,791 - HVD - INFO - 

VALIDATION
2024-12-16 20:55:33,791 - HVD - INFO - ==========
2024-12-16 21:01:00,660 - HVD - INFO - Presence: 0.67
2024-12-16 21:01:00,661 - HVD - INFO - Macro average: 0.67
2024-12-16 21:01:01,922 - HVD - INFO - UPLOAD to https://huggingface.co/Text-v8 (using HF_TOKEN environment variable)
2024-12-16 21:01:01,922 - HVD - INFO - SAVE to models
