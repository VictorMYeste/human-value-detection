Parsing arguments...
Building threshold map...
Computing weights from validation Macro-F1 …
Weights: {'1_TD-BERTopic_0.19_Baseline-val.tsv': '0.250', '1_TD-BERTopic_0.19_Lex-Schwartz-val.tsv': '0.248', '1_TD-BERTopic_0.19_Lex-EmoLex-val.tsv': '0.248', '1_TD-BERTopic_0.19_Lex-MFD-val.tsv': '0.254'}
Assembling...
Forward selection...
Seed model: 1_TD-BERTopic_0.19_Lex-MFD-val.tsv  (Macro-F1 = 0.29580)

Forward selection (weighted voting):
[Round 1]. Current Macro-Average F1 = 0.29580

Testing candidates: ['1_TD-BERTopic_0.19_Baseline-val.tsv', '1_TD-BERTopic_0.19_Lex-Schwartz-val.tsv', '1_TD-BERTopic_0.19_Lex-EmoLex-val.tsv']
  1_TD-BERTopic_0.19_Baseline-val.tsv lower=-0.01064 p=0.55300
  1_TD-BERTopic_0.19_Lex-Schwartz-val.tsv lower=-0.01201 p=0.95160
  1_TD-BERTopic_0.19_Lex-EmoLex-val.tsv lower=-0.01283 p=0.70980

Selected: ['1_TD-BERTopic_0.19_Lex-MFD-val.tsv']
Evaluating...

=== Final Weighted Ensemble (['1_TD-BERTopic_0.19_Lex-MFD-val.tsv']) ===
Macro-F1 Seed = 0.29580, Ensemble = 0.29580
One-sided lower 95% ΔF1 = 0.00000
p(ens>base) = 1.00000 -> significant? no
No per-label discordance on final ensemble.
Saving ensemble predictions...
Ensemble probabilities written to ../approaches/self-trans_moral-values/output/TD-BERTopic_0.19-tuned-weighted-champion-val.tsv
