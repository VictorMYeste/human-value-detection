2025-01-23 09:35:51,245 - datasets - INFO - PyTorch version 2.4.1+cu118 available.
2025-01-23 09:35:54,339 - HVD - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-01-23 09:35:54,536 - HVD - INFO - Loading lexicon embeddings for: No lexicon used
2025-01-23 09:35:54,536 - HVD - INFO - Preparing datasets for training and validation
2025-01-23 09:35:55,366 - HVD - INFO - Arguments validated successfully.
2025-01-23 09:35:55,880 - HVD - INFO - Using CUDA for training.
2025-01-23 09:35:57,149 - HVD - INFO - TRAINING
2025-01-23 09:35:57,149 - HVD - INFO - ========
2025-01-23 09:35:57,149 - HVD - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: Text-Custom-Stopwords-weightdecay-5
Batch size: 4
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.05
Gradient accumulation steps: 4
Early stopping patience: 4
Multilayer: No
Previous sentences used: No
Using lexicon: No
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 0

2025-01-23 09:35:57,155 - accelerate.utils.other - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'eval_loss': 0.7484090328216553, 'eval_f1-score': {'Presence': 0.72}, 'eval_marco-avg-f1-score': 0.72, 'eval_runtime': 14.0716, 'eval_samples_per_second': 71.065, 'eval_steps_per_second': 8.883, 'epoch': 0.99}
2025-01-23 09:36:44,604 - HVD - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'eval_loss': 0.8423283696174622, 'eval_f1-score': {'Presence': 0.72}, 'eval_marco-avg-f1-score': 0.72, 'eval_runtime': 14.1707, 'eval_samples_per_second': 70.568, 'eval_steps_per_second': 8.821, 'epoch': 1.98}
2025-01-23 09:37:29,557 - HVD - INFO - Skipping evaluation for warm-up phase (epoch 2).
{'eval_loss': 0.932772159576416, 'eval_f1-score': {'Presence': 0.72}, 'eval_marco-avg-f1-score': 0.72, 'eval_runtime': 14.0566, 'eval_samples_per_second': 71.141, 'eval_steps_per_second': 8.893, 'epoch': 2.98}
{'eval_loss': 0.7551289200782776, 'eval_f1-score': {'Presence': 0.72}, 'eval_marco-avg-f1-score': 0.72, 'eval_runtime': 14.1547, 'eval_samples_per_second': 70.648, 'eval_steps_per_second': 8.831, 'epoch': 4.0}
{'eval_loss': 0.8337253928184509, 'eval_f1-score': {'Presence': 0.72}, 'eval_marco-avg-f1-score': 0.72, 'eval_runtime': 14.1374, 'eval_samples_per_second': 70.735, 'eval_steps_per_second': 8.842, 'epoch': 4.99}
{'eval_loss': 0.9006618857383728, 'eval_f1-score': {'Presence': 0.72}, 'eval_marco-avg-f1-score': 0.72, 'eval_runtime': 14.1497, 'eval_samples_per_second': 70.673, 'eval_steps_per_second': 8.834, 'epoch': 5.98}
{'eval_loss': 0.9381325244903564, 'eval_f1-score': {'Presence': 0.69}, 'eval_marco-avg-f1-score': 0.69, 'eval_runtime': 14.1613, 'eval_samples_per_second': 70.615, 'eval_steps_per_second': 8.827, 'epoch': 6.98}
{'train_runtime': 326.3266, 'train_samples_per_second': 30.644, 'train_steps_per_second': 0.95, 'train_loss': 0.554086282712604, 'epoch': 6.98}
2025-01-23 09:41:24,003 - HVD - INFO - 

VALIDATION
2025-01-23 09:41:24,003 - HVD - INFO - ==========
2025-01-23 09:41:38,150 - HVD - INFO - Presence: 0.72
2025-01-23 09:41:38,150 - HVD - INFO - Macro average: 0.72
2025-01-23 09:41:38,900 - HVD - INFO - UPLOAD to https://huggingface.co/Text-Custom-Stopwords-weightdecay-5 (using HF_TOKEN environment variable)
2025-01-23 09:41:38,900 - HVD - INFO - SAVE to models
