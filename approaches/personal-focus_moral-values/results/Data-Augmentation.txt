2025-04-20 14:41:14,403 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-20 14:41:14,403 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-20 14:41:21,348 - INFO - Setting random seed to 42
2025-04-20 14:41:21,349 - INFO - Running training for labels: ['Self-direction: thought', 'Self-direction: action', 'Stimulation', 'Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face', 'Security: personal']
2025-04-20 14:41:21,349 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-04-20 14:41:21,758 - INFO - Loading lexicon embeddings for: No lexicon used
2025-04-20 14:41:21,758 - INFO - Preparing datasets for training and validation
2025-04-20 14:41:34,048 - INFO - Arguments validated successfully.
2025-04-20 14:41:34,051 - INFO - Previous sentences or augmented data detected. Adjusting batch size: 4 -> 2 and gradient accumulation steps: 4 -> 8
2025-04-20 14:41:34,051 - INFO - Clearing old checkpoints in models/checkpoints
2025-04-20 14:41:35,711 - INFO - Using CUDA for training.
2025-04-20 14:41:36,996 - INFO - TRAINING
2025-04-20 14:41:36,996 - INFO - ========
2025-04-20 14:41:36,996 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: None
Filter labels: ['Personal Focus']
Batch size: 2
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 8
Early stopping patience: 4
Multilayer: No
Previous sentences used: No
Using lexicon: No
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 0
Using data augmentation with paraphrasing: Yes
Adding topic detection features: No
Applying token pruning: No

2025-04-20 14:41:36,999 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.3294, 'grad_norm': 0.9508241415023804, 'learning_rate': 1.8763906056860324e-05, 'epoch': 0.62}
{'eval_loss': 0.25936493277549744, 'eval_f1-score': {'Self-direction: thought': 0, 'Self-direction: action': 0.09, 'Stimulation': 0.15, 'Hedonism': 0.21, 'Achievement': 0.56, 'Power: dominance': 0.46, 'Power: resources': 0.4, 'Face': 0.14, 'Security: personal': 0.46}, 'eval_macro-avg-f1-score': 0.27, 'eval_runtime': 47.2258, 'eval_samples_per_second': 80.613, 'eval_steps_per_second': 20.158, 'epoch': 1.0}
2025-04-20 15:05:10,672 - INFO - Skipping evaluation for warm-up phase (epoch 0).
{'loss': 0.2805, 'grad_norm': 1.572124719619751, 'learning_rate': 1.7527812113720642e-05, 'epoch': 1.24}
{'loss': 0.239, 'grad_norm': 2.2280948162078857, 'learning_rate': 1.6291718170580965e-05, 'epoch': 1.85}
{'eval_loss': 0.27459073066711426, 'eval_f1-score': {'Self-direction: thought': 0.16, 'Self-direction: action': 0.31, 'Stimulation': 0.29, 'Hedonism': 0.39, 'Achievement': 0.48, 'Power: dominance': 0.43, 'Power: resources': 0.49, 'Face': 0.27, 'Security: personal': 0.56}, 'eval_macro-avg-f1-score': 0.38, 'eval_runtime': 46.992, 'eval_samples_per_second': 81.014, 'eval_steps_per_second': 20.259, 'epoch': 2.0}
2025-04-20 15:28:40,869 - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'loss': 0.184, 'grad_norm': 2.798797130584717, 'learning_rate': 1.5055624227441288e-05, 'epoch': 2.47}
{'eval_loss': 0.33114632964134216, 'eval_f1-score': {'Self-direction: thought': 0.22, 'Self-direction: action': 0.31, 'Stimulation': 0.34, 'Hedonism': 0.37, 'Achievement': 0.52, 'Power: dominance': 0.5, 'Power: resources': 0.5, 'Face': 0.34, 'Security: personal': 0.54}, 'eval_macro-avg-f1-score': 0.4, 'eval_runtime': 47.0473, 'eval_samples_per_second': 80.919, 'eval_steps_per_second': 20.235, 'epoch': 3.0}
{'loss': 0.1488, 'grad_norm': 3.2453653812408447, 'learning_rate': 1.3819530284301607e-05, 'epoch': 3.09}
{'loss': 0.1037, 'grad_norm': 3.863441228866577, 'learning_rate': 1.2583436341161929e-05, 'epoch': 3.71}
{'eval_loss': 0.3893382251262665, 'eval_f1-score': {'Self-direction: thought': 0.14, 'Self-direction: action': 0.31, 'Stimulation': 0.32, 'Hedonism': 0.36, 'Achievement': 0.48, 'Power: dominance': 0.53, 'Power: resources': 0.49, 'Face': 0.32, 'Security: personal': 0.54}, 'eval_macro-avg-f1-score': 0.39, 'eval_runtime': 47.0869, 'eval_samples_per_second': 80.851, 'eval_steps_per_second': 20.218, 'epoch': 4.0}
{'loss': 0.078, 'grad_norm': 2.302079916000366, 'learning_rate': 1.134734239802225e-05, 'epoch': 4.32}
{'loss': 0.0624, 'grad_norm': 2.4131739139556885, 'learning_rate': 1.0111248454882572e-05, 'epoch': 4.94}
{'eval_loss': 0.43777674436569214, 'eval_f1-score': {'Self-direction: thought': 0.17, 'Self-direction: action': 0.33, 'Stimulation': 0.27, 'Hedonism': 0.37, 'Achievement': 0.52, 'Power: dominance': 0.54, 'Power: resources': 0.48, 'Face': 0.36, 'Security: personal': 0.52}, 'eval_macro-avg-f1-score': 0.4, 'eval_runtime': 46.9988, 'eval_samples_per_second': 81.002, 'eval_steps_per_second': 20.256, 'epoch': 5.0}
{'loss': 0.0444, 'grad_norm': 0.9154019951820374, 'learning_rate': 8.875154511742892e-06, 'epoch': 5.56}
{'eval_loss': 0.4781848192214966, 'eval_f1-score': {'Self-direction: thought': 0.15, 'Self-direction: action': 0.34, 'Stimulation': 0.3, 'Hedonism': 0.33, 'Achievement': 0.5, 'Power: dominance': 0.51, 'Power: resources': 0.48, 'Face': 0.36, 'Security: personal': 0.51}, 'eval_macro-avg-f1-score': 0.39, 'eval_runtime': 47.0924, 'eval_samples_per_second': 80.841, 'eval_steps_per_second': 20.216, 'epoch': 6.0}
{'loss': 0.0378, 'grad_norm': 0.9964672923088074, 'learning_rate': 7.639060568603214e-06, 'epoch': 6.18}
{'loss': 0.0299, 'grad_norm': 1.7856786251068115, 'learning_rate': 6.402966625463536e-06, 'epoch': 6.79}
{'eval_loss': 0.5092872381210327, 'eval_f1-score': {'Self-direction: thought': 0.15, 'Self-direction: action': 0.35, 'Stimulation': 0.34, 'Hedonism': 0.37, 'Achievement': 0.53, 'Power: dominance': 0.44, 'Power: resources': 0.51, 'Face': 0.32, 'Security: personal': 0.51}, 'eval_macro-avg-f1-score': 0.39, 'eval_runtime': 47.0218, 'eval_samples_per_second': 80.962, 'eval_steps_per_second': 20.246, 'epoch': 7.0}
{'train_runtime': 9884.4456, 'train_samples_per_second': 26.209, 'train_steps_per_second': 0.818, 'train_loss': 0.13642090053097247, 'epoch': 7.0}
2025-04-20 17:26:21,872 - INFO - 

VALIDATION
2025-04-20 17:26:21,872 - INFO - ==========
2025-04-20 17:27:08,831 - INFO - Self-direction: thought: 0.22
2025-04-20 17:27:08,831 - INFO - Self-direction: action: 0.31
2025-04-20 17:27:08,831 - INFO - Stimulation: 0.34
2025-04-20 17:27:08,831 - INFO - Hedonism: 0.37
2025-04-20 17:27:08,831 - INFO - Achievement: 0.52
2025-04-20 17:27:08,831 - INFO - Power: dominance: 0.50
2025-04-20 17:27:08,831 - INFO - Power: resources: 0.50
2025-04-20 17:27:08,831 - INFO - Face: 0.34
2025-04-20 17:27:08,831 - INFO - Security: personal: 0.54
2025-04-20 17:27:08,831 - INFO - Macro average: 0.40
2025-04-20 17:27:09,157 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
