2025-04-23 15:25:00,625 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-23 15:25:00,627 - INFO - PyTorch version 2.6.0+cu118 available.
2025-04-23 15:25:06,138 - INFO - Setting random seed to 42
2025-04-23 15:25:06,139 - INFO - Running training for labels: ['Hedonism', 'Achievement', 'Power: dominance', 'Power: resources', 'Face']
2025-04-23 15:25:06,139 - INFO - Initializing tokenizer for model: microsoft/deberta-base
2025-04-23 15:25:06,440 - INFO - Loading lexicon embeddings for: No lexicon used
2025-04-23 15:25:06,440 - INFO - Preparing datasets for training and validation
2025-04-23 15:25:06,630 - INFO - Pruning tokens in dataset '../../data/training-english/' (threshold=3.0)
2025-04-23 15:25:06,630 - INFO - Building IDF map from unpruned training text...
2025-04-23 15:25:06,792 - INFO - Token pruning (training): Average token count before pruning: 24.89
2025-04-23 15:25:06,857 - INFO - Token pruning (training): Average token count after pruning: 17.97 (Reduction: 6.92 tokens, 27.8% reduction)
2025-04-23 15:25:09,357 - INFO - Pruning tokens in dataset '../../data/validation-english/' (threshold=3.0)
2025-04-23 15:25:09,361 - INFO - Token pruning (validation): Average token count before pruning: 25.69
2025-04-23 15:25:09,384 - INFO - Token pruning (validation): Average token count after pruning: 18.61 (Reduction: 7.09 tokens, 27.6% reduction)
2025-04-23 15:25:10,139 - INFO - Arguments validated successfully.
2025-04-23 15:25:10,141 - INFO - Clearing old checkpoints in models/checkpoints
2025-04-23 15:25:11,679 - INFO - Using CUDA for training.
2025-04-23 15:25:12,984 - INFO - TRAINING
2025-04-23 15:25:12,984 - INFO - ========
2025-04-23 15:25:12,984 - INFO - Training configuration:
Pre-trained model: microsoft/deberta-base
Model name: None
Filter labels: ['Self-Enhancement']
Batch size: 4
Number of epochs: 10
Learning rate: 2e-05
Weight decay: 0.15
Gradient accumulation steps: 4
Early stopping patience: 4
Multilayer: No
ResidualBlock: No
Previous sentences used: No
Using lexicon: No
Adding linguistic features: No
Adding NER features: No
Number of categories (lexicon): 0
Using data augmentation with paraphrasing: No
Adding topic detection features: No
Applying token pruning: Yes

2025-04-23 15:25:12,987 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'eval_loss': 0.30121105909347534, 'eval_f1-score': {'Hedonism': 0.62, 'Achievement': 0.69, 'Power: dominance': 0.71, 'Power: resources': 0.69, 'Face': 0.43}, 'eval_macro-avg-f1-score': 0.63, 'eval_runtime': 20.2806, 'eval_samples_per_second': 129.483, 'eval_steps_per_second': 16.222, 'epoch': 1.0}
2025-04-23 15:28:01,936 - INFO - Skipping evaluation for warm-up phase (epoch 0).
{'loss': 0.328, 'grad_norm': 2.687998056411743, 'learning_rate': 1.6031746031746033e-05, 'epoch': 1.98}
{'eval_loss': 0.29418742656707764, 'eval_f1-score': {'Hedonism': 0.6, 'Achievement': 0.71, 'Power: dominance': 0.72, 'Power: resources': 0.67, 'Face': 0.42}, 'eval_macro-avg-f1-score': 0.62, 'eval_runtime': 20.256, 'eval_samples_per_second': 129.64, 'eval_steps_per_second': 16.242, 'epoch': 2.0}
2025-04-23 15:30:50,044 - INFO - Skipping evaluation for warm-up phase (epoch 1).
{'eval_loss': 0.3177594244480133, 'eval_f1-score': {'Hedonism': 0.59, 'Achievement': 0.71, 'Power: dominance': 0.74, 'Power: resources': 0.67, 'Face': 0.5}, 'eval_macro-avg-f1-score': 0.64, 'eval_runtime': 20.2546, 'eval_samples_per_second': 129.649, 'eval_steps_per_second': 16.243, 'epoch': 3.0}
{'loss': 0.1819, 'grad_norm': 1.8147239685058594, 'learning_rate': 1.2063492063492064e-05, 'epoch': 3.96}
{'eval_loss': 0.34783610701560974, 'eval_f1-score': {'Hedonism': 0.6, 'Achievement': 0.71, 'Power: dominance': 0.73, 'Power: resources': 0.67, 'Face': 0.5}, 'eval_macro-avg-f1-score': 0.64, 'eval_runtime': 20.2751, 'eval_samples_per_second': 129.518, 'eval_steps_per_second': 16.227, 'epoch': 4.0}
{'eval_loss': 0.3841058909893036, 'eval_f1-score': {'Hedonism': 0.63, 'Achievement': 0.69, 'Power: dominance': 0.74, 'Power: resources': 0.71, 'Face': 0.45}, 'eval_macro-avg-f1-score': 0.64, 'eval_runtime': 20.2161, 'eval_samples_per_second': 129.896, 'eval_steps_per_second': 16.274, 'epoch': 5.0}
{'loss': 0.0978, 'grad_norm': 4.108165264129639, 'learning_rate': 8.095238095238097e-06, 'epoch': 5.95}
{'eval_loss': 0.41055533289909363, 'eval_f1-score': {'Hedonism': 0.62, 'Achievement': 0.71, 'Power: dominance': 0.73, 'Power: resources': 0.71, 'Face': 0.51}, 'eval_macro-avg-f1-score': 0.66, 'eval_runtime': 20.2183, 'eval_samples_per_second': 129.882, 'eval_steps_per_second': 16.272, 'epoch': 6.0}
{'eval_loss': 0.46007612347602844, 'eval_f1-score': {'Hedonism': 0.65, 'Achievement': 0.7, 'Power: dominance': 0.73, 'Power: resources': 0.7, 'Face': 0.52}, 'eval_macro-avg-f1-score': 0.66, 'eval_runtime': 20.3268, 'eval_samples_per_second': 129.189, 'eval_steps_per_second': 16.186, 'epoch': 7.0}
{'loss': 0.0574, 'grad_norm': 3.094233274459839, 'learning_rate': 4.126984126984127e-06, 'epoch': 7.93}
{'eval_loss': 0.47317299246788025, 'eval_f1-score': {'Hedonism': 0.63, 'Achievement': 0.72, 'Power: dominance': 0.72, 'Power: resources': 0.69, 'Face': 0.49}, 'eval_macro-avg-f1-score': 0.65, 'eval_runtime': 20.3472, 'eval_samples_per_second': 129.06, 'eval_steps_per_second': 16.169, 'epoch': 8.0}
{'eval_loss': 0.48712247610092163, 'eval_f1-score': {'Hedonism': 0.62, 'Achievement': 0.71, 'Power: dominance': 0.72, 'Power: resources': 0.7, 'Face': 0.5}, 'eval_macro-avg-f1-score': 0.65, 'eval_runtime': 20.3419, 'eval_samples_per_second': 129.093, 'eval_steps_per_second': 16.174, 'epoch': 9.0}
{'loss': 0.0376, 'grad_norm': 7.719285011291504, 'learning_rate': 1.5873015873015874e-07, 'epoch': 9.91}
{'eval_loss': 0.49583548307418823, 'eval_f1-score': {'Hedonism': 0.64, 'Achievement': 0.72, 'Power: dominance': 0.72, 'Power: resources': 0.71, 'Face': 0.5}, 'eval_macro-avg-f1-score': 0.66, 'eval_runtime': 20.2452, 'eval_samples_per_second': 129.71, 'eval_steps_per_second': 16.251, 'epoch': 9.99}
{'train_runtime': 1706.6135, 'train_samples_per_second': 47.281, 'train_steps_per_second': 1.477, 'train_loss': 0.13975530612090278, 'epoch': 9.99}
2025-04-23 15:53:40,641 - INFO - 

VALIDATION
2025-04-23 15:53:40,641 - INFO - ==========
2025-04-23 15:54:00,569 - INFO - Hedonism: 0.62
2025-04-23 15:54:00,569 - INFO - Achievement: 0.71
2025-04-23 15:54:00,569 - INFO - Power: dominance: 0.73
2025-04-23 15:54:00,569 - INFO - Power: resources: 0.71
2025-04-23 15:54:00,569 - INFO - Face: 0.51
2025-04-23 15:54:00,569 - INFO - Macro average: 0.66
2025-04-23 15:54:00,854 - WARNING - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
